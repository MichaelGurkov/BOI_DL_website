---
title: "Convolutional Neural Network (CNN) for Image Classification"
---

Build, train, and evaluate a Convolutional Neural Network using the Sign Language MNIST dataset.


# Import and Load Data
- Import necessary libraries, including TensorFlow and Keras layers.
- Load the training and test datasets from CSV files.

```{r set_up_python, echo=FALSE}
#|echo: FALSE

if (Sys.getenv("USERPROFILE") == "C:\\Users\\internet"){
  
  python_path = "C:\\Users\\internet\\AppData\\Local\\Programs\\Python\\Python311\\python.exe"

} else {
  
  python_path = "C:\\Users\\Home\\AppData\\Local\\Programs\\Python\\Python311\\python.exe"
}

reticulate::use_python(python_path, required = TRUE)

```

```{python import_libraries}
#| code-fold: true
#| code-summary: "Show the code"


import pandas as pd

import numpy as np

import os

import matplotlib.pyplot as plt

from tensorflow.keras.utils import to_categorical

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout


```

```{python import_data}
#| code-fold: true
#| code-summary: "Show the code"


train_set = pd.read_csv(os.path.join(os.path.expanduser("~\\Documents\\BOI_DL_website"),
"data\\sign_mnist_train.csv"))

test_set = pd.read_csv(os.path.join(os.path.expanduser("~\\Documents\\BOI_DL_website"),
"data\\sign_mnist_test.csv"))


```

# Preprocessing
- Create a function to preprocess pixel values: normalize and reshape to `(28, 28, 1)`.
- Create a function to preprocess labels: remap classes to account for the missing letter 'J' and one-hot encode them.
- Apply the preprocessing functions to the training and test sets.

```{python auxilary_functions}
#| code-fold: true
#| code-summary: "Show the code"


def preprocess_data(df, img_height=28, img_width=28):
  
  processed_df = df / 255.0

  processed_df = processed_df.values.reshape(-1, img_height, img_width, 1).copy()

  return processed_df


def preprocess_labels(label_series, num_classes=24):
    """
    Remaps labels to skip index 9 (J) and applies one-hot encoding.

    Parameters:
    - label_series: a pandas Series or 1D array of labels (originally 0–25, with 9 missing)
    - num_classes: total number of actual classes (default 24)

    Returns:
    - One-hot encoded labels of shape (n_samples, num_classes)
    """
    labels = np.array(label_series)

    remapped_labels = np.array([l - 1 if l > 9 else l for l in labels])

    categorical_labels = to_categorical(remapped_labels, num_classes=num_classes)

    return categorical_labels


# Reverse the earlier remapping: add 1 to all labels ≥ 9
def reverse_remap(labels):
    return [l + 1 if l >= 9 else l for l in labels]



def show_predictions(x_data, y_true, y_pred, indices=None, n=6):
    if indices is None:
        indices = np.random.choice(len(x_data), n, replace=False)

    plt.figure(figsize=(12, 6))
    for i, idx in enumerate(indices):
        plt.subplot(2, n // 2, i + 1)
        plt.imshow(x_data[idx].reshape(28, 28), cmap='gray')
        plt.title(f"Pred: {y_pred[idx]}\nTrue: {y_true[idx]}")
        plt.axis('off')
    plt.tight_layout()
    plt.show()



```


```{python preprocessing}
#| code-fold: true
#| code-summary: "Show the code"



# Separate labels
y_train = preprocess_labels(train_set['label'])

y_test = preprocess_labels(test_set['label'])

# Remove labels from the pixel data
x_train = preprocess_data(train_set.drop('label', axis=1))

x_test = preprocess_data(test_set.drop('label', axis=1))

```

# Define CNN Model
- Construct a `Sequential` model with:
  - A `Conv2D` layer (32 filters, 3×3 kernel, ReLU, padding='same').
  - A `MaxPooling2D` layer (2×2).
  - Another `Conv2D` + `MaxPooling2D` block with 64 filters.
  - A `Flatten` layer.
  - A fully connected `Dense` layer with 128 units and ReLU activation.
  - A `Dropout` layer with rate 0.3.
  - A final `Dense` layer with 24 units and softmax activation.
- Compile the model using the Adam optimizer and categorical cross-entropy loss.

```{python define_model}
#| code-fold: true
#| code-summary: "Show the code"
#| output: false


model = Sequential([
    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(64, (3, 3), activation='relu', padding='same'),
    MaxPooling2D(pool_size=(2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(24, activation='softmax')  # 24 because of label remapping
])


model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)


```

# Train the Model
- Fit the model on the training data for 5 epochs with batch size 128.
- Use the test data as validation during training.

```{python fit_model}
#| code-fold: true
#| code-summary: "Show the code"
#| output: false


history = model.fit(
    x_train, y_train,
    validation_data=(x_test, y_test),
    epochs=5,
    batch_size=128,
    verbose = 0
)

```

# Evaluate the Model
- Evaluate the model on the test data.
- Report test accuracy.

```{python evaluation}
#| code-fold: true
#| code-summary: "Show the code"
#| output: false


loss, accuracy = model.evaluate(x_test, y_test)

print(f"Test Accuracy: {accuracy:.4f}")

```

# Visualizing Model Decisions with Grad-CAM

Convolutional Neural Networks are sometimes criticized for being “black boxes,” since it is not always clear what parts of an image the network relies on to make its prediction. To address this, visualization techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM) help us interpret and explain the model’s decisions.

Grad-CAM lets us see which parts of the image most influenced the model’s prediction by creating a heatmap of the regions the network “looked at” (based on gradients in the final convolutional layer). Here we first apply it to a single test image, and then to several misclassified examples to check whether the model is focusing on the relevant parts of the finger gesture.


```{python }
#| code-fold: true
#| code-summary: "Show the code"


# --- Grad-CAM: single example + misclassified overview -----------------------
# Assumes: 
#   - `model` is a trained CNN
#   - `x_test` is a NumPy array / tensor of test images with the model's expected shape
#   - `y_test` is one-hot labels (already remapped to 0..23, as in your pipeline)
#   - The last conv layer is named "conv2d_1" (adjust if your model differs)

from func_package.plotting import (
    plot_gradcam,           # returns a dict with heatmap, overlay, pred_index, etc.
    misclassified_indices,  # returns indices where model's argmax != true label
    plot_gradcam_grid       # draws a grid of Grad-CAM overlays for given indices
)

# ---- Single example ----------------------------------------------------------
# Compute and plot Grad-CAM for one test image (idx=0 by default).
# Internally, this evaluates gradients of the predicted logit w.r.t. the chosen conv layer
# to produce a heatmap highlighting influential spatial regions.
out = plot_gradcam(
    model, 
    x_test, 
    idx=1, 
    last_conv_layer_name="conv2d_1"
)

# Report the predicted class index (already remapped to 0..23 to match your label scheme).
print("Pred (remapped 0..23):", out["pred_index"])




```


```{python }
#| code-fold: true
#| code-summary: "Show the code"

# ---- Misclassified overview --------------------------------------------------
# Find which test samples are misclassified. `y_test` is one-hot, so this function
# compares argmax(model(x_i)) with argmax(y_i) and returns their indices.
bad = misclassified_indices(model, x_test, y_test)   # y_test is one-hot (remapped)


# Visualize the first 3 misclassifications as a Grad-CAM grid. This helps spot
# recurring failure modes (e.g., focusing on background rather than finger shape).
# Tip: If you want the “hardest” mistakes, sort/choose by model confidence before slicing.
plot_gradcam_grid(
    model, 
    x_test, 
    indices=bad[:3], 
    last_conv_layer_name="conv2d_1"
)

```

