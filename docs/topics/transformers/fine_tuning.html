<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Fine-Tuning BERT on TweetEval Sentiment</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-bce83624dd429190d13db9bf62533269.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#dataset-tweeteval-sentiment" id="toc-dataset-tweeteval-sentiment" class="nav-link active" data-scroll-target="#dataset-tweeteval-sentiment">Dataset: TweetEval Sentiment</a>
  <ul class="collapse">
  <li><a href="#dataset-size-before-downsampling" id="toc-dataset-size-before-downsampling" class="nav-link" data-scroll-target="#dataset-size-before-downsampling">Dataset Size (Before Downsampling)</a></li>
  </ul></li>
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization">Tokenization</a></li>
  <li><a href="#preparing-dataloaders" id="toc-preparing-dataloaders" class="nav-link" data-scroll-target="#preparing-dataloaders">Preparing DataLoaders</a></li>
  <li><a href="#baseline-model-no-fine-tuning" id="toc-baseline-model-no-fine-tuning" class="nav-link" data-scroll-target="#baseline-model-no-fine-tuning">Baseline Model (No Fine-Tuning)</a></li>
  <li><a href="#partial-fine-tuning" id="toc-partial-fine-tuning" class="nav-link" data-scroll-target="#partial-fine-tuning">Partial Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#what-fine-tuning-means-in-this-context" id="toc-what-fine-tuning-means-in-this-context" class="nav-link" data-scroll-target="#what-fine-tuning-means-in-this-context">What Fine-Tuning Means in This Context</a></li>
  </ul></li>
  <li><a href="#full-fine-tuning" id="toc-full-fine-tuning" class="nav-link" data-scroll-target="#full-fine-tuning">Full Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#what-makes-full-fine-tuning-different" id="toc-what-makes-full-fine-tuning-different" class="nav-link" data-scroll-target="#what-makes-full-fine-tuning-different">What Makes Full Fine-Tuning Different?</a></li>
  <li><a href="#why-full-fine-tuning-usually-performs-best" id="toc-why-full-fine-tuning-usually-performs-best" class="nav-link" data-scroll-target="#why-full-fine-tuning-usually-performs-best">Why Full Fine-Tuning Usually Performs Best</a></li>
  </ul></li>
  <li><a href="#comparing-the-three-models" id="toc-comparing-the-three-models" class="nav-link" data-scroll-target="#comparing-the-three-models">Comparing the Three Models</a>
  <ul class="collapse">
  <li><a href="#what-learns-in-each-model" id="toc-what-learns-in-each-model" class="nav-link" data-scroll-target="#what-learns-in-each-model">What Learns in Each Model?</a></li>
  <li><a href="#why-these-differences-matter" id="toc-why-these-differences-matter" class="nav-link" data-scroll-target="#why-these-differences-matter">Why These Differences Matter</a></li>
  <li><a href="#why-comparison-matters" id="toc-why-comparison-matters" class="nav-link" data-scroll-target="#why-comparison-matters">Why Comparison Matters</a></li>
  <li><a href="#what-we-expect-to-see" id="toc-what-we-expect-to-see" class="nav-link" data-scroll-target="#what-we-expect-to-see">What We Expect to See</a></li>
  </ul></li>
  <li><a href="#qualitative-comparison" id="toc-qualitative-comparison" class="nav-link" data-scroll-target="#qualitative-comparison">Qualitative Comparison</a>
  <ul class="collapse">
  <li><a href="#how-each-model-behaves-on-individual-tweets" id="toc-how-each-model-behaves-on-individual-tweets" class="nav-link" data-scroll-target="#how-each-model-behaves-on-individual-tweets">How Each Model Behaves on Individual Tweets</a></li>
  <li><a href="#what-we-look-for-in-this-comparison" id="toc-what-we-look-for-in-this-comparison" class="nav-link" data-scroll-target="#what-we-look-for-in-this-comparison">What We Look For in This Comparison</a></li>
  </ul></li>
  <li><a href="#summary-from-zero-shot-to-full-fine-tuning" id="toc-summary-from-zero-shot-to-full-fine-tuning" class="nav-link" data-scroll-target="#summary-from-zero-shot-to-full-fine-tuning">Summary: From Zero-Shot to Full Fine-Tuning</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Fine-Tuning BERT on TweetEval Sentiment</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install -q transformers datasets accelerate</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertTokenizerFast</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"tweet_eval"</span>, <span class="st">"sentiment"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>N_train <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>N_val   <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>] <span class="op">=</span> dataset[<span class="st">"train"</span>].select(<span class="bu">range</span>(N_train))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"validation"</span>] <span class="op">=</span> dataset[<span class="st">"validation"</span>].select(<span class="bu">range</span>(N_val))</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> BertTokenizerFast.from_pretrained(<span class="st">"bert-base-uncased"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="dataset-tweeteval-sentiment" class="level2">
<h2 class="anchored" data-anchor-id="dataset-tweeteval-sentiment">Dataset: TweetEval Sentiment</h2>
<p>For this tutorial we use the <strong>TweetEval Sentiment</strong> dataset, a benchmark collection of tweets labeled for sentiment analysis. The dataset was introduced as part of the TweetEval benchmark, which unifies several Twitter NLP tasks under a common framework.</p>
<p>The sentiment subset contains tweets annotated with three classes:</p>
<ul>
<li><strong>0 — Negative</strong></li>
<li><strong>1 — Neutral</strong></li>
<li><strong>2 — Positive</strong></li>
</ul>
<p>TweetEval is well-suited for fine-tuning transformer models because:</p>
<ul>
<li>Tweets contain slang, emojis, irregular grammar, abbreviations, and sarcasm.</li>
<li>These characteristics make the domain challenging for general pre-trained models.</li>
<li>Fine-tuning allows BERT to adapt from formal text (BooksCorpus, Wikipedia) to the informal, noisy style of Twitter.</li>
</ul>
<section id="dataset-size-before-downsampling" class="level3">
<h3 class="anchored" data-anchor-id="dataset-size-before-downsampling">Dataset Size (Before Downsampling)</h3>
<p>The full dataset includes approximately:</p>
<ul>
<li><strong>45,000 tweets</strong> for training<br>
</li>
<li><strong>12,000 tweets</strong> for validation<br>
</li>
<li><strong>2,000 tweets</strong> for testing</li>
</ul>
<p>Since full training can be slow during development, this notebook uses a <strong>downsampled version</strong></p>
</section>
</section>
<section id="tokenization" class="level2">
<h2 class="anchored" data-anchor-id="tokenization">Tokenization</h2>
<p>Before we can feed text into BERT, we must convert each tweet into the numerical format that the model expects. BERT does not work directly with raw strings—it operates on token IDs and attention masks. The tokenizer performs this conversion and applies several important preprocessing steps.</p>
<p>BERT uses a <strong>WordPiece tokenizer</strong>, which breaks text into subword units. This allows the model to handle noisy and informal language often found in tweets, including slang, abbreviations, hashtags, and even misspellings. If a word is not in the vocabulary, it is decomposed into smaller subwords that BERT can still interpret meaningfully.</p>
<p>During tokenization, the tokenizer also:</p>
<ul>
<li><strong>Adds special tokens</strong> such as <code>[CLS]</code> (classification token) and <code>[SEP]</code> (separator).</li>
<li><strong>Truncates</strong> sequences so they fit within a fixed maximum length (64 tokens in this tutorial).</li>
<li><strong>Pads</strong> shorter sequences so all inputs are the same length.</li>
<li><strong>Builds an attention mask</strong>, which tells BERT which tokens are real and which are padding.</li>
</ul>
<p>After tokenization, each example in the dataset contains:</p>
<ul>
<li><code>input_ids</code>: the numerical tokens representing the text<br>
</li>
<li><code>attention_mask</code>: indicators showing which positions should be attended to<br>
</li>
<li><code>label</code>: the sentiment class</li>
</ul>
<p>We apply the tokenizer to the entire dataset using the <code>map()</code> function and then reformat the output so it can be used directly with PyTorch.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_batch(batch):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        batch[<span class="st">"text"</span>],</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"max_length"</span>,</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">64</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(tokenize_batch, batched<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> tokenized_dataset.remove_columns([<span class="st">"text"</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>tokenized_dataset.set_format(</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">type</span><span class="op">=</span><span class="st">"torch"</span>,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"input_ids"</span>, <span class="st">"attention_mask"</span>, <span class="st">"label"</span>]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="preparing-dataloaders" class="level2">
<h2 class="anchored" data-anchor-id="preparing-dataloaders">Preparing DataLoaders</h2>
<p>After tokenization, the dataset contains all the components BERT needs—<code>input_ids</code>, <code>attention_mask</code>, and <code>label</code>. The next step is to prepare these examples for efficient training.</p>
<p>Neural networks in PyTorch expect data to be provided through <strong>DataLoaders</strong>, which handle batching, shuffling, and iteration over the dataset. This is especially important for transformer models, where training is computationally intensive and must be performed in batches that fit into GPU memory.</p>
<p>We construct two DataLoaders:</p>
<ul>
<li><p><strong>Training DataLoader</strong><br>
Shuffles the data at every epoch to prevent the model from learning order-specific patterns and to encourage better generalization.</p></li>
<li><p><strong>Validation DataLoader</strong><br>
Does not shuffle the data and is used to evaluate model performance after training without introducing randomness.</p></li>
</ul>
<p>Each batch produced by the DataLoader contains:</p>
<ul>
<li>a tensor of tokenized tweets (<code>input_ids</code>)</li>
<li>a tensor of attention masks (<code>attention_mask</code>)</li>
<li>a tensor of labels</li>
</ul>
<p>These will be passed directly into BERT during training and evaluation. Creating DataLoaders ensures that the model receives input in a structured, optimized, and reproducible format.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating DataLoaders for training and validation</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    tokenized_dataset[<span class="st">"train"</span>],</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    tokenized_dataset[<span class="st">"validation"</span>],</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="baseline-model-no-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="baseline-model-no-fine-tuning">Baseline Model (No Fine-Tuning)</h2>
<p>Before applying any supervised training, it is essential to establish a <strong>baseline performance level</strong>. This baseline measures how well a pre-trained BERT model performs <em>without</em> learning anything about sentiment classification and <em>without</em> adapting to the style of Twitter language.</p>
<p>BERT is trained on large, general-purpose corpora (BooksCorpus and Wikipedia), but it has <strong>never been exposed to sentiment labels</strong> and has <strong>never been trained on the informal, noisy structure of tweets</strong>. Tweets differ from formal text in several ways: they are short, contain slang, emojis, abbreviations, hashtags, and often rely on irony or sarcasm. A pretrained BERT encoder, used as-is, typically performs poorly on such data.</p>
<p>To evaluate this, we construct a model by attaching a small <strong>classification head</strong> to the <code>[CLS]</code> embedding produced by BERT. This head is required because BERT alone cannot output sentiment labels; it only produces contextual representations. In the baseline scenario:</p>
<ul>
<li>all of BERT’s encoder parameters are <strong>frozen</strong>,<br>
</li>
<li>the classification head remains <strong>randomly initialized</strong>,<br>
</li>
<li>no supervised training is performed on either component,<br>
</li>
<li>the model therefore performs <strong>zero-shot</strong> sentiment classification.</li>
</ul>
<p>Zero-shot here means that the model has seen <strong>zero sentiment-labeled examples</strong> during training; it relies solely on BERT’s general language understanding and a random classifier.</p>
<p>Evaluating this zero-shot model gives us a meaningful lower bound:<br>
<strong>How well does BERT handle tweet sentiment without any supervised training or domain adaptation?</strong></p>
<p>This baseline accuracy will later serve as a reference point when comparing partial and full fine-tuning results.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Baseline Model (No Fine-Tuning)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertForSequenceClassification</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load a pre-trained BERT classifier</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>baseline_model <span class="op">=</span> BertForSequenceClassification.from_pretrained(</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"bert-base-uncased"</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">3</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze all encoder layers → no fine-tuning</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> baseline_model.bert.parameters():</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation function</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate(model, data_loader):</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    correct, total <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> data_loader:</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            ids <span class="op">=</span> batch[<span class="st">"input_ids"</span>].to(device)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            mask <span class="op">=</span> batch[<span class="st">"attention_mask"</span>].to(device)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> batch[<span class="st">"label"</span>].to(device)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> model(ids, attention_mask<span class="op">=</span>mask).logits</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            preds <span class="op">=</span> torch.argmax(logits, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> (preds <span class="op">==</span> y).<span class="bu">sum</span>().item()</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> y.size(<span class="dv">0</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> correct <span class="op">/</span> total</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="partial-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="partial-fine-tuning">Partial Fine-Tuning</h2>
<section id="what-fine-tuning-means-in-this-context" class="level3">
<h3 class="anchored" data-anchor-id="what-fine-tuning-means-in-this-context">What Fine-Tuning Means in This Context</h3>
<p>Fine-tuning is a <strong>supervised learning process</strong> in which BERT is trained on labeled examples for a specific downstream task—in this case, sentiment classification. During fine-tuning, the model receives tweet–label pairs such as:</p>
<ul>
<li>“I love this!” → Positive<br>
</li>
<li>“This is awful.” → Negative<br>
</li>
<li>“It’s okay, I guess.” → Neutral</li>
</ul>
<p>By learning from these supervised labels, BERT adjusts its internal parameters so that its representations become more useful for predicting sentiment. This is fundamentally different from the baseline model, where no labeled training occurs and no parameters are updated. Fine-tuning therefore means:</p>
<ul>
<li>the model learns from <strong>labeled sentiment data</strong>,<br>
</li>
<li>selected parameters are updated during training,<br>
</li>
<li>performance improves significantly over the zero-shot baseline.</li>
</ul>
<p>With this definition in place, we now describe how <em>partial</em> fine-tuning selectively updates only the upper layers of BERT while keeping the lower layers frozen.</p>
<hr>
<p>The baseline model demonstrates how poorly a pre-trained BERT performs when it is not adapted to the TweetEval domain. To improve performance while still keeping computational cost low, we apply <strong>partial fine-tuning</strong>.</p>
<p>BERT consists of 12 transformer encoder layers stacked on top of one another. The lower layers typically learn general linguistic features such as token identity, morphology, and short-range dependencies. The upper layers capture more <strong>task-specific</strong> information, including sentiment cues and semantic relationships.</p>
<p>In partial fine-tuning, we freeze the <strong>lower encoder layers</strong> (layers 0–8) and train only the <strong>upper layers</strong> (layers 9–11) together with the classification head. This approach:</p>
<ul>
<li>reduces the number of trainable parameters,<br>
</li>
<li>speeds up training,<br>
</li>
<li>lowers VRAM requirements,<br>
</li>
<li>reduces the risk of overfitting on a small dataset,<br>
</li>
<li>still allows BERT to learn important domain-specific patterns from tweets.</li>
</ul>
<p>Partial fine-tuning typically yields a large improvement in accuracy compared to the baseline while remaining efficient enough to run quickly in environments like Google Colab.</p>
<p>The next code block implements partial fine-tuning for one epoch and evaluates its performance.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Partial Fine-Tuning (train upper layers only)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertForSequenceClassification</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> AdamW</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load a fresh BERT model</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>partial_model <span class="op">=</span> BertForSequenceClassification.from_pretrained(</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"bert-base-uncased"</span>,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">3</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze lower BERT layers: 0–8</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer_idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> param <span class="kw">in</span> partial_model.bert.encoder.layer[layer_idx].parameters():</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Train only layers 9, 10, 11 + classifier head</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>trainable_params <span class="op">=</span> [p <span class="cf">for</span> p <span class="kw">in</span> partial_model.parameters() <span class="cf">if</span> p.requires_grad]</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> AdamW(trainable_params, lr<span class="op">=</span><span class="fl">2e-5</span>)</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="co"># One training epoch</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>partial_model.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    ids <span class="op">=</span> batch[<span class="st">"input_ids"</span>].to(device)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> batch[<span class="st">"attention_mask"</span>].to(device)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> batch[<span class="st">"label"</span>].to(device)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> partial_model(ids, attention_mask<span class="op">=</span>mask, labels<span class="op">=</span>y)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> outputs.loss</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="full-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="full-fine-tuning">Full Fine-Tuning</h2>
<p>Partial fine-tuning restricts learning to the upper encoder layers, allowing BERT to adjust some of its representations while keeping the lower layers fixed. To give the model maximal flexibility, we now perform <strong>full fine-tuning</strong>, where <strong>every parameter in the network is updated</strong> based on labeled sentiment examples.</p>
<section id="what-makes-full-fine-tuning-different" class="level3">
<h3 class="anchored" data-anchor-id="what-makes-full-fine-tuning-different">What Makes Full Fine-Tuning Different?</h3>
<p>In full fine-tuning:</p>
<ul>
<li><strong>All 12 transformer layers are trainable</strong>,<br>
</li>
<li>The attention heads inside each layer are updated,<br>
</li>
<li>The intermediate feedforward networks are updated,<br>
</li>
<li>Layer normalization parameters are updated,<br>
</li>
<li>The classification head is updated as well.</li>
</ul>
<p>This means the entire model — from low-level token embeddings to high-level semantics — can adapt to the specific characteristics of Twitter language.</p>
<p>Full fine-tuning is the complete opposite of the baseline:</p>
<ul>
<li>In the baseline: <strong>no supervised learning</strong> occurs and all encoder weights remain fixed.<br>
</li>
<li>In partial fine-tuning: <strong>only the upper layers and classifier learn</strong>.<br>
</li>
<li>In full fine-tuning: <strong>all layers and the classifier learn simultaneously</strong>.</li>
</ul>
<p>Because sentiment classification is a supervised task, full fine-tuning allows BERT to integrate the sentiment labels deeply into every layer of its internal representation.</p>
</section>
<section id="why-full-fine-tuning-usually-performs-best" class="level3">
<h3 class="anchored" data-anchor-id="why-full-fine-tuning-usually-performs-best">Why Full Fine-Tuning Usually Performs Best</h3>
<p>Tweets contain irregular grammar, emojis, sarcasm, abbreviations, and other linguistic patterns that differ significantly from BERT’s pretraining domain. When all parameters are trainable, the model can:</p>
<ul>
<li>refine embeddings for informal vocabulary,<br>
</li>
<li>adjust attention patterns to better detect sentiment cues,<br>
</li>
<li>reorganize its semantic space around the three sentiment labels,<br>
</li>
<li>learn subtle distinctions that partial tuning cannot fully capture.</li>
</ul>
<p>The trade-offs are higher computational cost and potentially longer training time, but the improvement in performance is typically notable.</p>
<p>The next code block performs one epoch of full fine-tuning and then evaluates the model on the validation set.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Full Fine-Tuning (train ALL layers)</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertForSequenceClassification</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> AdamW</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Load a fresh BERT model for full fine-tuning</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>full_model <span class="op">=</span> BertForSequenceClassification.from_pretrained(</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"bert-base-uncased"</span>,</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    num_labels<span class="op">=</span><span class="dv">3</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Unfreeze ALL parameters → full end-to-end training</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> full_model.parameters():</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">True</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Count total trainable parameters</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>trainable_params <span class="op">=</span> [p <span class="cf">for</span> p <span class="kw">in</span> full_model.parameters() <span class="cf">if</span> p.requires_grad]</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> AdamW(trainable_params, lr<span class="op">=</span><span class="fl">2e-5</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="co"># One training epoch</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>full_model.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    ids <span class="op">=</span> batch[<span class="st">"input_ids"</span>].to(device)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> batch[<span class="st">"attention_mask"</span>].to(device)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> batch[<span class="st">"label"</span>].to(device)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> full_model(ids, attention_mask<span class="op">=</span>mask, labels<span class="op">=</span>y)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> outputs.loss</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="comparing-the-three-models" class="level2">
<h2 class="anchored" data-anchor-id="comparing-the-three-models">Comparing the Three Models</h2>
<p>Now that we have trained all three versions of the model—baseline, partial fine-tuning, and full fine-tuning—we can compare their performance directly. Understanding <strong>which parts of the model are allowed to learn</strong> is essential for interpreting these results.</p>
<section id="what-learns-in-each-model" class="level3">
<h3 class="anchored" data-anchor-id="what-learns-in-each-model">What Learns in Each Model?</h3>
<ul>
<li><p><strong>Baseline (Zero-Shot)</strong></p>
<ul>
<li>BERT encoder: <strong>frozen</strong></li>
<li>Classification head: <strong>untrained</strong></li>
<li>Supervised learning: <strong>none</strong></li>
</ul>
<p>The model makes predictions using BERT’s general language understanding and a random classifier. No part of the network adapts to sentiment labels or Twitter-style text.</p></li>
<li><p><strong>Partial Fine-Tuning</strong></p>
<ul>
<li>BERT layers 0–8: <strong>frozen</strong></li>
<li>BERT layers 9–11: <strong>trainable</strong></li>
<li>Classification head: <strong>trainable</strong></li>
<li>Supervised learning: <strong>upper encoder layers + classifier</strong></li>
</ul>
<p>The model can learn high-level sentiment cues but keeps foundational linguistic representations fixed.</p></li>
<li><p><strong>Full Fine-Tuning</strong></p>
<ul>
<li>All BERT layers: <strong>trainable</strong></li>
<li>Classification head: <strong>trainable</strong></li>
<li>Supervised learning: <strong>entire model</strong></li>
</ul>
<p>Every parameter in BERT adjusts to sentiment labels and Twitter’s linguistic characteristics.</p></li>
</ul>
</section>
<section id="why-these-differences-matter" class="level3">
<h3 class="anchored" data-anchor-id="why-these-differences-matter">Why These Differences Matter</h3>
<p>Evaluating the models side by side clearly demonstrates the effect of supervision:</p>
<ul>
<li>The <strong>baseline</strong> reflects how poorly a non-adapted model handles Twitter sentiment.<br>
</li>
<li><strong>Partial fine-tuning</strong> often yields a large performance boost by allowing only the upper semantic layers to adapt.<br>
</li>
<li><strong>Full fine-tuning</strong> typically achieves the best performance because all layers participate in learning the sentiment task.</li>
</ul>
<p>This progression — from zero learning, to partial learning, to full learning — illustrates the core principle of transfer learning with BERT.</p>
<p>The following code block prints the accuracy of each model for direct comparison.</p>
</section>
<section id="why-comparison-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-comparison-matters">Why Comparison Matters</h3>
<p>Evaluating all three models side by side reveals:</p>
<ul>
<li><p><strong>The impact of domain mismatch:</strong><br>
The baseline model performs poorly because raw BERT has never seen the structure of tweets, which often include emojis, slang, abbreviations, and informal grammar.</p></li>
<li><p><strong>The benefit of partial fine-tuning:</strong><br>
Training only the top transformer layers allows the model to adjust its higher-level semantic representations, significantly improving accuracy without updating the entire network.</p></li>
<li><p><strong>The advantages of full fine-tuning:</strong><br>
Updating all layers gives the model maximal flexibility to adapt to the tweet domain, typically yielding the highest performance.</p></li>
</ul>
</section>
<section id="what-we-expect-to-see" class="level3">
<h3 class="anchored" data-anchor-id="what-we-expect-to-see">What We Expect to See</h3>
<ul>
<li>Baseline accuracy: very low<br>
</li>
<li>Partial fine-tuning: large improvement<br>
</li>
<li>Full fine-tuning: best performance overall</li>
</ul>
<p>This comparison provides the clearest demonstration of why fine-tuning is essential in modern NLP workflows. The next code block prints all three accuracies side by side.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>baseline_acc <span class="op">=</span> evaluate(baseline_model, val_loader)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>partial_acc <span class="op">=</span> evaluate(partial_model, val_loader)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>full_acc <span class="op">=</span> evaluate(full_model, val_loader)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect metrics into a DataFrame</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Model"</span>: [</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Baseline (no fine-tuning)"</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Partial fine-tuning"</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Full fine-tuning"</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Accuracy"</span>: [</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">round</span>(baseline_acc, <span class="dv">4</span>),</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">round</span>(partial_acc, <span class="dv">4</span>),</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">round</span>(full_acc, <span class="dv">4</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                       Model  Accuracy
0  Baseline (no fine-tuning)     0.422
1        Partial fine-tuning     0.556
2           Full fine-tuning     0.566</code></pre>
</div>
</div>
</section>
</section>
<section id="qualitative-comparison" class="level2">
<h2 class="anchored" data-anchor-id="qualitative-comparison">Qualitative Comparison</h2>
<p>Numerical accuracy provides a useful summary, but qualitative examples make the differences between the three models immediately visible. By examining real tweets, we can observe how each model behaves based on <strong>which parts of the network were allowed to learn</strong>.</p>
<section id="how-each-model-behaves-on-individual-tweets" class="level3">
<h3 class="anchored" data-anchor-id="how-each-model-behaves-on-individual-tweets">How Each Model Behaves on Individual Tweets</h3>
<ul>
<li><p><strong>Baseline (Zero-Shot)</strong></p>
<ul>
<li>BERT encoder: frozen<br>
</li>
<li>Classifier: untrained<br>
</li>
<li>No supervised learning</li>
</ul>
<p>Because neither the encoder nor the classifier has seen sentiment labels, the model often misinterprets sentiment cues, ignores emojis, and fails to recognize sarcasm or informal grammar. Predictions may appear arbitrary or overly biased toward one class.</p></li>
<li><p><strong>Partial Fine-Tuning</strong></p>
<ul>
<li>Only upper BERT layers + classifier learn<br>
</li>
<li>Lower linguistic layers remain fixed</li>
</ul>
<p>This model improves considerably on clear sentiment cues—positive phrases, strong negative language, common emoji patterns. However, it may still struggle with subtle or ambiguous cases because only part of the model adapted to the task.</p></li>
<li><p><strong>Full Fine-Tuning</strong></p>
<ul>
<li>All BERT layers learn from supervised labels</li>
</ul>
<p>This model generally provides the most reliable and stable predictions. It adapts deeply to Twitter’s informal style, handles emojis better, and captures sentiment even in short or noisy tweets. Sarcasm and ambiguous expressions may still be difficult, but performance is consistently superior.</p></li>
</ul>
</section>
<section id="what-we-look-for-in-this-comparison" class="level3">
<h3 class="anchored" data-anchor-id="what-we-look-for-in-this-comparison">What We Look For in This Comparison</h3>
<p>By comparing the predictions of all three models on the same tweet, we can see:</p>
<ul>
<li>how <strong>supervised learning</strong> changes the model’s understanding,<br>
</li>
<li>how much improvement occurs when more layers are allowed to adapt,<br>
</li>
<li>how full fine-tuning overcomes many of the weaknesses of the zero-shot and partially tuned models.</li>
</ul>
<p>The next code block selects random validation tweets and prints the predictions from all three models alongside their true labels.</p>
<div class="cell">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Qualitative Comparison: Predictions on Sample Tweets</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>label_names <span class="op">=</span> dataset[<span class="st">"train"</span>].features[<span class="st">"label"</span>].names</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Select 10 random validation examples</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(dataset[<span class="st">"validation"</span>])), <span class="dv">10</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">=== QUALITATIVE MODEL COMPARISON ===</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
=== QUALITATIVE MODEL COMPARISON ===</code></pre>
</div>
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> indices:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> dataset[<span class="st">"validation"</span>][idx][<span class="st">"text"</span>]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> label_names[dataset[<span class="st">"validation"</span>][idx][<span class="st">"label"</span>]]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tokenize a single tweet</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        text,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">"pt"</span>,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">64</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    ).to(device)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predictions from each model</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    baseline_pred <span class="op">=</span> label_names[baseline_model(<span class="op">**</span>inputs).logits.argmax(dim<span class="op">=</span><span class="dv">1</span>).item()]</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    partial_pred  <span class="op">=</span> label_names[partial_model(<span class="op">**</span>inputs).logits.argmax(dim<span class="op">=</span><span class="dv">1</span>).item()]</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    full_pred     <span class="op">=</span> label_names[full_model(<span class="op">**</span>inputs).logits.argmax(dim<span class="op">=</span><span class="dv">1</span>).item()]</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Tweet: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"True label:       </span><span class="sc">{</span>true_label<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Baseline:         </span><span class="sc">{</span>baseline_pred<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Partial-tuned:    </span><span class="sc">{</span>partial_pred<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Full-tuned:       </span><span class="sc">{</span>full_pred<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Tweet: @user it was soo good meeting you again on Tuesday! Worth the track from Liverpool to Wakefield:D!
True label:       positive
Baseline:         positive
Partial-tuned:    positive
Full-tuned:       positive
--------------------------------------------------------------------------------
Tweet: We just received more tickets for Blue Rodeo at The KEE to Bala Saturday May 19th and Sunday May 20th. Tickets...
True label:       neutral
Baseline:         positive
Partial-tuned:    neutral
Full-tuned:       neutral
--------------------------------------------------------------------------------
Tweet: MT @user My 1st read of the day from @user Congress returns to tight deadlines, key farts on Iran deal, Planned Parenthood
True label:       negative
Baseline:         positive
Partial-tuned:    positive
Full-tuned:       neutral
--------------------------------------------------------------------------------
Tweet: @user is true that you will give two concerts in Mexico City on 01 &amp; October 02, please tell me because not enough tickets TE AMO"
True label:       positive
Baseline:         positive
Partial-tuned:    neutral
Full-tuned:       neutral
--------------------------------------------------------------------------------
Tweet: 3rd season Dance Academy means to me : going crazy! I love it and can't wait :)))
True label:       positive
Baseline:         positive
Partial-tuned:    positive
Full-tuned:       positive
--------------------------------------------------------------------------------
Tweet: @user Did you watch the 1st episode of American Horror Story yet so you can understand why I refuse to watch the rest of it ?!?!?
True label:       negative
Baseline:         positive
Partial-tuned:    positive
Full-tuned:       positive
--------------------------------------------------------------------------------
Tweet: "Steve Jobs: Source: www.quotationspage.com --- Sunday, August 14, 2011\""You can't just ask customers what they wa...
True label:       neutral
Baseline:         positive
Partial-tuned:    neutral
Full-tuned:       neutral
--------------------------------------------------------------------------------
Tweet: @user There is more Islam in Austria than in Saudi Arabia and the Gulf states. May Allah bless these Austrian folks.@sunnysingh_nw3
True label:       positive
Baseline:         positive
Partial-tuned:    neutral
Full-tuned:       positive
--------------------------------------------------------------------------------
Tweet: Man I hope she doesn't Frank Ocean us
True label:       neutral
Baseline:         neutral
Partial-tuned:    positive
Full-tuned:       neutral
--------------------------------------------------------------------------------
Tweet: @user I think that may be what Kesha's mother meant by she helped her
True label:       neutral
Baseline:         positive
Partial-tuned:    neutral
Full-tuned:       neutral
--------------------------------------------------------------------------------</code></pre>
</div>
</div>
</section>
</section>
<section id="summary-from-zero-shot-to-full-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="summary-from-zero-shot-to-full-fine-tuning">Summary: From Zero-Shot to Full Fine-Tuning</h2>
<p>This notebook demonstrates the full progression of adapting BERT to a supervised sentiment classification task:</p>
<ol type="1">
<li><strong>Baseline (Zero-Shot)</strong>
<ul>
<li>No supervised learning<br>
</li>
<li>BERT encoder frozen<br>
</li>
<li>Classifier untrained<br>
</li>
<li>Predictions come from general language knowledge only</li>
</ul></li>
<li><strong>Partial Fine-Tuning</strong>
<ul>
<li>Upper BERT layers + classifier learn from labeled data<br>
</li>
<li>Lower layers remain frozen<br>
</li>
<li>Model adapts partially to sentiment cues and Twitter language</li>
</ul></li>
<li><strong>Full Fine-Tuning</strong>
<ul>
<li>Every parameter in the network learns<br>
</li>
<li>Model fully adapts to both the task and the domain<br>
</li>
<li>Highest performance and most robust predictions</li>
</ul></li>
</ol>
<p>This progression illustrates how supervised fine-tuning transforms BERT from a general-purpose text encoder into a task-specific sentiment classifier. The baseline shows how little BERT understands tweet sentiment without labeled training, partial fine-tuning demonstrates the benefit of updating high-level semantic layers, and full fine-tuning provides the strongest results by allowing all layers to adjust to the task.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>