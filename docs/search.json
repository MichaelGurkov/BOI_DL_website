[
  {
    "objectID": "topics/single_layer/single_layer_credit_score.html",
    "href": "topics/single_layer/single_layer_credit_score.html",
    "title": "Single layer Neural Network for Credit Score classification",
    "section": "",
    "text": "In this tutorial we build and evaluate a single hidden layer neural network to predict credit default risk (SeriousDlqin2yrs, 0/1). The model:\n\nUses one hidden layer with ReLU activation\nOutputs a probability via sigmoid\nTrains using full-batch gradient descent (one update per epoch)\nEvaluates accuracy, AUC, precision, recall, and F1\nWe standardize features to improve optimization stability.\n\n\n\n\nTarget: SeriousDlqin2yrs — whether serious delinquency occurred within 2 years (0/1).\nFeatures: 10 standardized numeric predictors (after cleaning and dropping the ID column).\n\n\n\nShow the code\n\nimport os\n# Core data handling\nimport numpy as np                  # numeric arrays, vectorized ops\nimport pandas as pd                 # dataframes, CSV I/O\n\n# Model selection & preprocessing\nfrom sklearn.model_selection import train_test_split   # train/test split with stratify\nfrom sklearn.preprocessing import StandardScaler       # feature standardization (fit on train only!)\n\n# Deep learning (Keras/TensorFlow)\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential                # simple stack model\nfrom tensorflow.keras.layers import Dense, Input       # fully connected layers\nfrom tensorflow.keras import metrics                   # ready-made metrics: AUC, Precision, Recall, F1",
    "crumbs": [
      "Credit Score example"
    ]
  },
  {
    "objectID": "topics/single_layer/single_layer_credit_score.html#overview",
    "href": "topics/single_layer/single_layer_credit_score.html#overview",
    "title": "Single layer Neural Network for Credit Score classification",
    "section": "",
    "text": "In this tutorial we build and evaluate a single hidden layer neural network to predict credit default risk (SeriousDlqin2yrs, 0/1). The model:\n\nUses one hidden layer with ReLU activation\nOutputs a probability via sigmoid\nTrains using full-batch gradient descent (one update per epoch)\nEvaluates accuracy, AUC, precision, recall, and F1\nWe standardize features to improve optimization stability.\n\n\n\n\nTarget: SeriousDlqin2yrs — whether serious delinquency occurred within 2 years (0/1).\nFeatures: 10 standardized numeric predictors (after cleaning and dropping the ID column).\n\n\n\nShow the code\n\nimport os\n# Core data handling\nimport numpy as np                  # numeric arrays, vectorized ops\nimport pandas as pd                 # dataframes, CSV I/O\n\n# Model selection & preprocessing\nfrom sklearn.model_selection import train_test_split   # train/test split with stratify\nfrom sklearn.preprocessing import StandardScaler       # feature standardization (fit on train only!)\n\n# Deep learning (Keras/TensorFlow)\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential                # simple stack model\nfrom tensorflow.keras.layers import Dense, Input       # fully connected layers\nfrom tensorflow.keras import metrics                   # ready-made metrics: AUC, Precision, Recall, F1",
    "crumbs": [
      "Credit Score example"
    ]
  },
  {
    "objectID": "topics/single_layer/single_layer_credit_score.html#data-preprocessing",
    "href": "topics/single_layer/single_layer_credit_score.html#data-preprocessing",
    "title": "Single layer Neural Network for Credit Score classification",
    "section": "Data preprocessing",
    "text": "Data preprocessing\nBefore training, we need to prepare the dataset:\n\nRemove rows with missing values.\n\nSeparate features (X) from the target (y = SeriousDlqin2yrs).\n\nSplit into training and test sets (keeping class balance with stratify).\n\nStandardize features so each has mean 0 and variance 1 — this helps the neural net train smoothly.\n\n\n\nShow the code\ndef preprocess_data(df):\n    \"\"\"\n    Clean, split, and scale the dataset for classification.\n    \"\"\"\n    # 1) Remove rows with missing values\n    df = df.dropna()\n\n    # 2) Separate features and target\n    X = df.drop(\"SeriousDlqin2yrs\", axis=1)\n    y = df[\"SeriousDlqin2yrs\"]\n\n    # 3) Train/test split with stratification to preserve class ratio\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n\n    # 4) Standardize features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled  = scaler.transform(X_test)\n\n    return X_train_scaled, X_test_scaled, y_train, y_test\n\n\n\n\nShow the code\n# Path to the dataset (inside Documents/BOI_DL_website/data)\ndata_path = os.path.join(\n    os.path.expanduser(\"~\\\\Documents\\\\BOI_DL_website\"),\n    \"data\\\\credit_small_sample.csv\"\n)\n\n# Load raw dataset\nraw_df = pd.read_csv(data_path)\n\n# Apply preprocessing: clean → split → scale\nX_train, X_test, y_train, y_test = preprocess_data(raw_df)",
    "crumbs": [
      "Credit Score example"
    ]
  },
  {
    "objectID": "topics/single_layer/single_layer_credit_score.html#model-architecture-training-setup",
    "href": "topics/single_layer/single_layer_credit_score.html#model-architecture-training-setup",
    "title": "Single layer Neural Network for Credit Score classification",
    "section": "Model architecture & training setup",
    "text": "Model architecture & training setup\nWe will build a single-hidden-layer neural network:\n\nInput (10 features): the standardized predictors from preprocessing.\n\nHidden layer: Dense(20, ReLU)\n\nReLU introduces nonlinearity and allows the model to learn flexible decision boundaries.\n\n\nOutput layer: Dense(1, Sigmoid) produces a probability of default in ([0,1]).\n\nLoss: binary_crossentropy to match the probabilistic output.\n\nOptimizer: Adam with learning rate 1e-3.\n\nMetrics: accuracy, AUC, precision, recall, and F1 for a balanced evaluation under class imbalance.\n\nTraining: 25 epochs using full-batch gradient descent.\n\nFull-batch training means:\n\nThe entire training set is used as one batch.\n\nEach epoch performs one forward pass and one weight update.\n\nThis approach is feasible because the dataset is small.\n\n\n\n\nThe multi-layer neural network used in this tutorial. It takes 10 standardized input features, passes them through two hidden layers (60 and 5 neurons with ReLU activations), and produces a single sigmoid output that represents the probability of default.\n\n\n\n\nShow the code\n# Define a simple feed-forward neural network\nmodel = Sequential([\n    Input(shape=(10,)),                         # The model expects 10 standardized input features\n    Dense(20, activation=\"relu\",                # Hidden layer with 20 neurons + ReLU non-linearity\n          kernel_initializer=\"uniform\"),        # Initialize weights uniformly (small random values)\n    Dense(1, activation=\"sigmoid\")              # Output layer: sigmoid gives probability of default\n])\n\n# Specify training configuration\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-3),   # Adam optimizer with learning rate = 0.001\n    loss=\"binary_crossentropy\",                 # Standard loss function for binary classification\n    metrics=[\n        \"accuracy\",                             # Proportion of correct predictions\n        metrics.AUC(name=\"auc\"),                # Area under ROC curve (ranking quality)\n        metrics.Precision(name=\"precision\"),    # TP / (TP + FP) — “how many predicted positives are real”\n        metrics.Recall(name=\"recall\"),          # TP / (TP + FN) — “how many true positives we catch”\n        metrics.F1Score(name=\"f1\")              # Harmonic mean of precision and recall\n    ]\n)\n\n# Use full-batch gradient descent: one weight update per epoch\nbatch_size = X_train.shape[0]\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    epochs=25,                                  # Number of passes through the full dataset\n    batch_size=batch_size,                      # Full batch = whole dataset at once\n    verbose=0                                   # Suppress training output for cleaner logs\n)",
    "crumbs": [
      "Credit Score example"
    ]
  },
  {
    "objectID": "topics/single_layer/single_layer_credit_score.html#model-evaluation",
    "href": "topics/single_layer/single_layer_credit_score.html#model-evaluation",
    "title": "Single layer Neural Network for Credit Score classification",
    "section": "Model evaluation",
    "text": "Model evaluation\nAfter training, we test the model on the held-out test set.\nThe evaluate function returns the loss and all metrics we specified in compile (accuracy, AUC, precision, recall, F1).\nPresenting them in a clean, rounded format makes the results easier to interpret.\n\n\nShow the code\n# Evaluate on the test set and return metrics as a dictionary\ntest_metrics = model.evaluate(X_test, y_test, verbose=0, return_dict=True)\n\n# Format nicely: metric name + rounded value\nfor key, value in test_metrics.items():\n    print(f\"{key:&lt;10}: {value:.2f}\")\n\n\naccuracy  : 0.93\nauc       : 0.63\nf1        : 0.13\nloss      : 0.61\nprecision : 0.60\nrecall    : 0.02",
    "crumbs": [
      "Credit Score example"
    ]
  },
  {
    "objectID": "topics/single_layer/single_layer_credit_score.html#training-history",
    "href": "topics/single_layer/single_layer_credit_score.html#training-history",
    "title": "Single layer Neural Network for Credit Score classification",
    "section": "Training history",
    "text": "Training history\nLooking at metrics across epochs helps us understand model behavior:\n\nLoss curve: should generally decrease; if it rises again, the model may be overfitting.\n\nAccuracy / AUC curves: should increase and stabilize.\n\nPrecision/recall tradeoff: sometimes one rises while the other falls; looking at both is important.\n\nPlotting the training history gives a clear picture of how the network improves during training.\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\n# Convert training history to a DataFrame for easy plotting\nhistory_df = pd.DataFrame(history.history)\n\n# Plot loss\nplt.figure(figsize=(6,4))\nplt.plot(history_df[\"loss\"], label=\"Training loss\")\nplt.title(\"Training loss over epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nShow the code\n# Plot accuracy and AUC\nplt.figure(figsize=(6,4))\nplt.plot(history_df[\"accuracy\"], label=\"Accuracy\")\nplt.plot(history_df[\"auc\"], label=\"AUC\")\nplt.title(\"Training metrics over epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Metric value\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Credit Score example"
    ]
  },
  {
    "objectID": "topics/single_layer/single_layer_credit_score.html#appendix-metrics-formulas",
    "href": "topics/single_layer/single_layer_credit_score.html#appendix-metrics-formulas",
    "title": "Single layer Neural Network for Credit Score classification",
    "section": "Appendix: Metrics & Formulas",
    "text": "Appendix: Metrics & Formulas\nThis page reports binary classification metrics computed on a held-out test set.\nLet TP, FP, TN, FN be counts from the confusion matrix at a threshold \\(t\\) (often \\(t=0.5\\)).\nLet \\(y_{i} \\in \\{0,1\\}\\) be the true label and \\(\\hat{p}_i \\in [0,1]\\) the model’s predicted probability for the positive class.\n\nBinary Cross-Entropy (Log Loss)\nMeasures the quality of probabilistic predictions (lower is better): \\[\n\\text{BCE} = -\\frac{1}{n}\\sum_{i=1}^{n}\\Big[y_i \\log(\\hat{p}_i) + (1-y_i)\\log\\big(1-\\hat{p}_i\\big)\\Big].\n\\]\n\nProper scoring rule: encourages calibrated probabilities.\nUsed as the training loss for the sigmoid output.\n\n\n\nAccuracy\nShare of correct predictions at threshold (t): \\[\n\\text{Accuracy} = \\frac{TP + TN}{TP + FP + TN + FN}.\n\\]\n\nCan be misleading under class imbalance.\n\n\n\nPrecision (Positive Predictive Value)\n“How many predicted positives are truly positive?”\n\\[\n\\text{Precision} = \\frac{TP}{TP + FP}.\n\\]\n\n\nRecall (Sensitivity, TPR)\n“How many actual positives did we catch?”\n\\[\n\\text{Recall} = \\frac{TP}{TP + FN}.\n\\]\n\n\nF1 Score\nHarmonic mean of precision and recall: \\[\n\\text{F1} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n= \\frac{2TP}{2TP + FP + FN}.\n\\]\n\nBalances miss rate (FN) vs. false alarms (FP).\nGeneralization: \\(F_\\beta\\) weights recall \\(\\beta\\) times more than precision:\n\n\\[\nF_\\beta = (1+\\beta^2)\\,\\frac{\\text{Precision}\\cdot\\text{Recall}}{(\\beta^2\\cdot\\text{Precision})+\\text{Recall}}.\n\\]\n\n\nAUC (ROC-AUC)\nThreshold-free measure of ranking quality (higher is better).\n- ROC curve: plot \\(\\text{TPR}=\\frac{TP}{TP+FN}\\) vs. \\(\\text{FPR}=\\frac{FP}{FP+TN}\\) as \\(t\\) varies.\n\nAUC is the area under the ROC curve and equals the probability a random positive is ranked above a random negative: \\[\n\\text{AUC} = \\Pr\\big(\\hat{p}^+ &gt; \\hat{p}^-\\big).\n\\]\n\n\n\nPractical Notes\n\nThreshold choice ((t)) trades precision vs. recall; tune (t) to business costs or by maximizing a metric (e.g., F1) on validation data.\nImbalanced data: rely less on accuracy; prefer AUC, PR curves, F1, and class-specific error analysis.\nCalibration: well-calibrated \\(\\hat{p}\\) improves decision-making when costs vary",
    "crumbs": [
      "Credit Score example"
    ]
  },
  {
    "objectID": "topics/single_layer/classification.html",
    "href": "topics/single_layer/classification.html",
    "title": "Single layer Neural Network for Binary Classification",
    "section": "",
    "text": "Implement a simple neural network from scratch and compare its performance to logistic regression on a 2D dataset.\nShow the code\n\nimport pandas as pd\n\nimport numpy as np\n\nimport os",
    "crumbs": [
      "Classification"
    ]
  },
  {
    "objectID": "topics/single_layer/classification.html#auxiliary-functions",
    "href": "topics/single_layer/classification.html#auxiliary-functions",
    "title": "Single layer Neural Network for Binary Classification",
    "section": "Auxiliary functions",
    "text": "Auxiliary functions\n\nImplement Training Functions\n\nDefine helper functions for activation, parameter initialization, forward/backward propagation, and parameter update.\n\n\n\nShow the activation function code\nimport numpy as np\n\n\ndef activate(Z, activation_function=\"tanh\"):\n    \"\"\"\n    Apply an activation function elementwise.\n    \"\"\"\n    if activation_function == \"tanh\":\n        return np.tanh(Z)  # squashes values to [-1, 1]\n    elif activation_function == \"sigmoid\":\n        return 1.0 / (1.0 + np.exp(-Z))  # squashes values to [0, 1]\n    else:\n        raise ValueError(\"activation_function must be 'tanh' or 'sigmoid'.\")\n\n\n\n\nShow the parameters initialization code\nimport numpy as np\n\n\ndef initialize_parameters(X, num_hidden_layer_neurons, scale_const=0.01, seed=1):\n    \"\"\"\n    Initialize weights and biases for a single hidden-layer network.\n    \"\"\"\n    np.random.seed(seed)\n\n    n_features = X.shape[1]  # number of input features\n\n    # Small random weights help avoid saturation of activations at start\n    W1 = np.random.randn(num_hidden_layer_neurons, n_features) * scale_const\n    b1 = np.zeros((num_hidden_layer_neurons, 1))\n    W2 = np.random.randn(1, num_hidden_layer_neurons) * scale_const\n    b2 = np.zeros((1, 1))\n\n    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n\n\n\n\n\nForward and backward propagation in a single-hidden-layer neural network. The forward pass takes inputs \\(X\\) through weights \\(W^{[1]}, W^{[2]}\\) and biases \\(b^{[1]}, b^{[2]}\\) to produce pre-activations \\(Z^{[1]}, Z^{[2]}\\), activations \\(A^{[1]}, A^{[2]}\\), and final output \\(y\\). The backward pass computes gradients of activations, pre-activations, weights, and biases \\((dA, dZ, dW, db)\\) from the output layer back to the input layer for parameter updates.\n\n\n\n\nShow the forward propagation code\nimport numpy as np\n\n\ndef forward_propagation(parameters, X_adj):\n    \"\"\"\n    Perform one forward pass.\n    \"\"\"\n    W1, b1, W2, b2 = parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"], parameters[\"b2\"]\n\n    Z1 = np.dot(W1, X_adj) + b1  # linear transform: hidden layer\n    A1 = activate(Z1, \"tanh\")    # non-linear activation for hidden layer\n    Z2 = np.dot(W2, A1) + b2     # linear transform: output layer\n    A2 = activate(Z2, \"sigmoid\") # probability output for binary classification\n\n    return {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n\n\n\n\nShow the backward propagation code\nimport numpy as np\n\n\ndef backward_propagation(parameters, forward_propagation_values, X_adj, Y_adj):\n    \"\"\"\n    Compute gradients for parameters using backpropagation.\n    \"\"\"\n    N = X_adj.shape[1]  # number of samples\n\n    W2 = parameters[\"W2\"]\n    A1, A2 = forward_propagation_values[\"A1\"], forward_propagation_values[\"A2\"]\n\n    dZ2 = A2 - Y_adj                      # derivative of loss w.r.t. Z2 (sigmoid+BCE Loss)\n    dW2 = np.dot(dZ2, A1.T) / N           # gradient for W2\n    db2 = np.sum(dZ2, axis=1, keepdims=True) / N  # gradient for b2\n\n    dZ1 = np.dot(W2.T, dZ2) * (1 - A1**2) # backprop through tanh: derivative is 1 - A1^2\n    dW1 = np.dot(dZ1, X_adj.T) / N        # gradient for W1\n    db1 = np.sum(dZ1, axis=1, keepdims=True) / N  # gradient for b1\n\n    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n\n\n\n\nShow the parameters update code\nimport numpy as np\n\ndef update_parameters(parameters, grads, learning_rate=0.01):\n    \"\"\"\n    Update parameters using gradient descent.\n    \"\"\"\n    # subtract learning_rate * gradient for each parameter\n    W1 = parameters[\"W1\"] - learning_rate * grads[\"dW1\"]\n    b1 = parameters[\"b1\"] - learning_rate * grads[\"db1\"]\n    W2 = parameters[\"W2\"] - learning_rate * grads[\"dW2\"]\n    b2 = parameters[\"b2\"] - learning_rate * grads[\"db2\"]\n\n    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n\n\n\nCreate a wrapper function train_neural_network to run the training loop.\n\n\n\nShow the neural network training code\ndef train_neural_network(X, Y, num_iterations, num_hidden_layer_neurons=4):\n    \"\"\"\n    Trains a simple 1-hidden-layer neural network using gradient descent.\n    \"\"\"\n    # Transpose X so columns are examples, reshape Y to row vector\n    X_adj = X.T.copy()                         \n    Y_adj = Y.values.reshape(1, -1).copy()     \n\n    # Initialize weights and biases\n    parameters = initialize_parameters(X, num_hidden_layer_neurons=num_hidden_layer_neurons)\n\n    for iteration in range(num_iterations):\n        # Forward pass\n        forward_values = forward_propagation(parameters, X_adj.copy())\n\n        # Backward pass\n        grads = backward_propagation(parameters, forward_values, X_adj.copy(), Y_adj.copy())\n\n        # Parameter update\n        parameters = update_parameters(parameters, grads)\n\n    return parameters\n\n\n\n\nImplement Prediction Function\n\nCreate a predict function that runs forward propagation and thresholds outputs.\n\n\n\nShow the code\ndef predict(nn_parameters, X, threshold=0.5):\n    \"\"\"\n    Generates binary predictions from a trained neural network.\n    \"\"\"\n    # Transpose X so columns are examples\n    X_adj = X.T.copy()\n\n    # Forward pass to get output layer activations\n    forward_values = forward_propagation(nn_parameters, X_adj.copy())\n\n    # Output probabilities from sigmoid\n    y_pred = forward_values[\"A2\"]\n\n    # Apply threshold to get class labels {0,1}\n    y_pred = y_pred &gt; threshold\n\n    return y_pred.astype(int).ravel()  # flatten to 1D array",
    "crumbs": [
      "Classification"
    ]
  },
  {
    "objectID": "topics/single_layer/classification.html#derivation-sigmoid-binary-cross-entropy",
    "href": "topics/single_layer/classification.html#derivation-sigmoid-binary-cross-entropy",
    "title": "Single layer Neural Network for Binary Classification",
    "section": "Derivation: Sigmoid + Binary Cross-Entropy",
    "text": "Derivation: Sigmoid + Binary Cross-Entropy\nWe can show that using a sigmoid activation in the output layer with binary cross-entropy (BCE) loss leads to a very simple gradient formula.\nGoal \\[\n\\frac{\\partial L}{\\partial z} = a - y\n\\]\nSetup For a single example with label \\(y \\in \\{0,1\\}\\): \\[\nz = W^{[2]} a^{[1]} + b^{[2]}, \\qquad a = \\sigma(z) = \\frac{1}{1+e^{-z}}\n\\] The BCE loss for this example is: \\[\n\\ell(a,y) = -\\big[y \\log a + (1-y)\\log(1-a)\\big]\n\\] For a batch of \\(N\\) examples: \\[\nL = \\frac{1}{N}\\sum_{i=1}^N \\ell\\!\\big(a^{(i)}, y^{(i)}\\big)\n\\]\nStep 1 (loss wrt \\(a\\)) \\[\n\\frac{\\partial \\ell}{\\partial a}\n= -\\!\\left(\\frac{y}{a} - \\frac{1-y}{1-a}\\right)\n= \\frac{a - y}{a(1-a)}\n\\]\nStep 2 (sigmoid derivative) \\[\n\\frac{\\partial a}{\\partial z} = a(1-a)\n\\]\nStep 3 (chain rule) \\[\n\\frac{\\partial \\ell}{\\partial z}\n= \\frac{\\partial \\ell}{\\partial a}\\cdot\\frac{\\partial a}{\\partial z}\n= \\frac{a - y}{a(1-a)} \\cdot a(1-a)\n= a - y\n\\]\nBatch form \\[\n\\frac{\\partial L}{\\partial Z} = \\frac{1}{N}(A - Y)\n\\]\nCode correspondence\n\ndZ2 = A2 - Y_adj\n\ndW2 = np.dot(dZ2, A1.T) / N\n\ndb2 = np.sum(dZ2, axis=1, keepdims=True) / N",
    "crumbs": [
      "Classification"
    ]
  },
  {
    "objectID": "topics/single_layer/classification.html#neural-network-architecture-playbook",
    "href": "topics/single_layer/classification.html#neural-network-architecture-playbook",
    "title": "Single layer Neural Network for Binary Classification",
    "section": "Neural Network Architecture Playbook",
    "text": "Neural Network Architecture Playbook\nDefinitions - Depth: The number of hidden layers stacked between input and output.\n- Width: The number of neurons in each hidden layer.\n(Let d be the number of input features.)\n\nStep 1 — Build a small, trainable baseline\n\nStart with 1–3 hidden layers.\n\nSet hidden layer sizes as multiples of d (e.g., d, 2d, 4d).\n\nAdd dropout (0–0.5) and weight decay (AdamW) for regularization.\n\nAlways keep a validation split and monitor training/validation curves.\n\n\n\nStep 2 — Diagnose with learning curves\n\nUnderfitting (high train & val error): widen hidden layers first, then add more layers if needed.\n\nOverfitting (low train, high val): add data/augmentation; increase dropout or weight decay; use early stopping; simplify by reducing neurons or layers.\n\nOptimization issues (unstable or diverging): lower the learning rate; adjust batch size; use better initialization; consider normalization.\n\n\n\nStep 3 — Grow capacity deliberately\n\nIncrease width modestly before adding depth.\n\nIf you deepen the network, add residual connections or normalization to stabilize training.\n\nIncrease epochs only once the model trains stably.\n\n\n\nStep 4 — Tune by systematic search\n\nUse Random Search or Hyperband over:\n\nLayers: {1, 2, 3, 4, 6}\n\nWidths: {d, 2d, 4d, 8d}\n\nDropout: [0, 0.5]\n\nWeight decay: small grid (e.g., 1e-6 … 1e-3)",
    "crumbs": [
      "Classification"
    ]
  },
  {
    "objectID": "topics/python_workshop/python_workshop.html",
    "href": "topics/python_workshop/python_workshop.html",
    "title": "Python for Deep Learning",
    "section": "",
    "text": "This hands-on workshop introduces the essential Python skills needed for deep learning. You’ll run Python code in Google Colab.\n\n\n\n\nShow the code\nimport pandas as pd\nimport numpy as np\nimport os\n\n\n\n\nGet familiar with Python’s basic building blocks: variables, lists, dictionaries, control flow, and functions.\n\n\n\nLists and dictionaries\nif, for, and while statements\nWriting and calling functions\n\n\n\n\nConcept:\n- Lists are ordered collections. Each item has a position called an index (starting from 0).\n- You can get a single element using list[index] (e.g., scores[0] → first element).\n- You can get a slice using list[start:stop], which returns elements from start up to but not including stop.\n- Dictionaries store key–value pairs. You look up a value by its key (like a label).\n- You can add new keys or update existing ones using dict[key] = value.\n- Keys must be unique; values can be any data type.\n\n# A list of exam scores for Alice\nscores_alice = [88, 92, 79]\n\n# Indexing: position 0 is the first score\nprint(\"First score:\", scores_alice[0])\n\nFirst score: 88\n\n# Slicing: [:2] means start at index 0, stop before index 2 → positions 0 and 1\nprint(\"First two scores:\", scores_alice[:2])\n\nFirst two scores: [88, 92]\n\n# A dictionary mapping student names to their list of scores\nstudent_scores = {\n    \"Alice\": [88, 92, 79],\n    \"Bob\":   [75, 83, 80],\n    \"Carol\": [90, 85, 95],\n    \"Dave\":  [72, 78, 70],\n}\n\n# Lookup: use the key (student's name) to get the list of scores\nprint(\"Carol's scores:\", student_scores[\"Carol\"])\n\nCarol's scores: [90, 85, 95]\n\n# Add a new student by assigning to a new key\nstudent_scores[\"Eve\"] = [85, 88, 91]\n\n# Update an existing student's scores (overwrites the old list)\nstudent_scores[\"Bob\"] = [78, 84, 82]\n\n# Get all keys (student names) and values (lists of scores)\nprint(\"Students:\", list(student_scores.keys()))\n\nStudents: ['Alice', 'Bob', 'Carol', 'Dave', 'Eve']\n\nprint(\"Sample scores:\", list(student_scores.values())[:2])  # [:2] → first two values\n\nSample scores: [[88, 92, 79], [78, 84, 82]]\n\n\n\n\n\nConcept:\n- if / elif / else lets the program choose actions based on conditions.\n- for loops iterate over items in a collection, letting you process each element in turn.\nWe’ll use the student_scores dictionary from the previous section.\n\n# Example 1: if / elif / else\nx = 87\nif x &gt;= 90:\n    grade = \"A\"\nelif x &gt;= 80:\n    grade = \"B\"\nelse:\n    grade = \"C or below\"\nprint(\"Grade bucket:\", grade)\n\nGrade bucket: B\n\n# Example 2: for loop over a student's scores\n# Reusing the student_scores dictionary from earlier\nscores_alice = student_scores[\"Alice\"]  # a list of Alice's scores\ntotal = 0\nfor s in scores_alice:\n    total = total + s\naverage = total / len(scores_alice)\nprint(\"Alice's average score:\", average)\n\nAlice's average score: 86.33333333333333\n\n\n\n\n\nConcept:\n- A function is a reusable block of code that takes inputs (parameters) and can return an output.\n- Use def function_name(parameters): to define it.\n- Use return to send a result back to the caller.\n- You can reuse loops and calculations inside a function so you don’t repeat the same code.\n\ndef average_score(scores):\n    \"\"\"\n    Calculate the average from a list of scores.\n    \"\"\"\n    total = 0\n    for s in scores:\n        total = total + s\n    return total / len(scores)\n\n# Example: Calculate averages for all students\nfor name in student_scores:  # loops over keys (student names)\n    avg = average_score(student_scores[name])\n    print(f\"{name}: {avg:.2f}\")\n\nAlice: 86.33\nBob: 81.33\nCarol: 90.00\nDave: 73.33\nEve: 88.00\n\n\n\n\n\n\nConcept:\nNumPy arrays are like lists but optimized for fast mathematical operations.\n- 1D array → like a row of numbers.\n- 2D array → like a table (rows × columns).\n- .shape tells you the size of the array.\n\n# 1D array: vector of exam scores\nscores_1d = np.array([88, 92, 79])\nprint(\"1D array:\", scores_1d)\n\n1D array: [88 92 79]\n\nprint(\"Shape:\", scores_1d.shape)  # (3,) → 3 elements in 1 dimension\n\nShape: (3,)\n\n# 2D array: scores for two students across three exams\nscores_2d = np.array([\n    [88, 92, 79],  # student 1\n    [75, 83, 80]   # student 2\n])\nprint(\"\\n2D array:\\n\", scores_2d)\n\n\n2D array:\n [[88 92 79]\n [75 83 80]]\n\nprint(\"Shape:\", scores_2d.shape)  # (2, 3) → 2 rows, 3 columns\n\nShape: (2, 3)\n\n# Now convert student_scores dictionary values into a 2D array\ngrades_matrix = np.array(list(student_scores.values()))\nprint(\"\\nGrades matrix:\\n\", grades_matrix)\n\n\nGrades matrix:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\nprint(\"Shape:\", grades_matrix.shape)  # rows = students, columns = exams\n\nShape: (5, 3)\n\n\n\n\nConcept:\n- Indexing works like Python lists: array[row_index, col_index] (0-based).\n- Slicing lets you select a range: start:stop returns elements from start up to (but not including) stop.\n- You can slice rows, columns, or both.\n\n# Example array for reference\nprint(\"Grades matrix:\\n\", grades_matrix)\n\nGrades matrix:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\n# Get the score of the first student in the first exam\nprint(\"\\nFirst student's first exam score:\", grades_matrix[0, 0])\n\n\nFirst student's first exam score: 88\n\n# Get all exam scores for the second student (row index 1)\nprint(\"Second student's scores:\", grades_matrix[1, :])\n\nSecond student's scores: [78 84 82]\n\n# Get all scores for the third exam (column index 2)\nprint(\"Scores in third exam:\", grades_matrix[:, 2])\n\nScores in third exam: [79 82 95 70 91]\n\n# Slice: first two students' scores\nprint(\"First two students' scores:\\n\", grades_matrix[0:2, :])\n\nFirst two students' scores:\n [[88 92 79]\n [78 84 82]]\n\n# Slice: first two exams for all students\nprint(\"First two exams for all students:\\n\", grades_matrix[:, 0:2])\n\nFirst two exams for all students:\n [[88 92]\n [78 84]\n [90 85]\n [72 78]\n [85 88]]\n\n\n\n\n\nConcept:\n- Element-wise operations apply a calculation to each element of an array.\n- Broadcasting lets NumPy apply operations between arrays of different shapes by “stretching” one to match the other (without copying data).\n- This is much faster and cleaner than using Python loops.\n\n# Add 5 points to every score (element-wise addition)\nprint(\"Original:\\n\", grades_matrix)\n\nOriginal:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\nprint(\"\\n+5 to every score:\\n\", grades_matrix + 5)\n\n\n+5 to every score:\n [[ 93  97  84]\n [ 83  89  87]\n [ 95  90 100]\n [ 77  83  75]\n [ 90  93  96]]\n\n# Multiply all scores by 1.1 to simulate a 10% bonus\nprint(\"\\n10% bonus:\\n\", grades_matrix * 1.1)\n\n\n10% bonus:\n [[ 96.8 101.2  86.9]\n [ 85.8  92.4  90.2]\n [ 99.   93.5 104.5]\n [ 79.2  85.8  77. ]\n [ 93.5  96.8 100.1]]\n\n# Broadcasting: subtract the minimum score in each column (exam) from that column\nmin_scores_per_exam = grades_matrix.min(axis=0)  # shape: (n_exams,)\nprint(\"\\nMinimum scores per exam:\", min_scores_per_exam)\n\n\nMinimum scores per exam: [72 78 70]\n\nadjusted = grades_matrix - min_scores_per_exam  # broadcasting happens here\nprint(\"\\nScores adjusted by exam minimum:\\n\", adjusted)\n\n\nScores adjusted by exam minimum:\n [[16 14  9]\n [ 6  6 12]\n [18  7 25]\n [ 0  0  0]\n [13 10 21]]\n\n\n\n\n\nConcept:\n- Matrix multiplication (np.dot) combines rows and columns, often used in deep learning layers to combine inputs with weights.\n- Axis-based operations let you apply functions (mean, sum, etc.) across rows or columns:\n\naxis=0 → operate down columns (across rows)\naxis=1 → operate across columns (per row)\n\nExtra notes: - np.ones(shape) creates an array of ones with the given shape.\n- Here we use it for equal weights when averaging scores: each exam gets the same weight.\n- .flatten() converts a multi-dimensional array into a 1D array.\n- After matrix multiplication, the result might be shape (n_students, 1); flattening makes it easier to print and work with.\n\n\n\nMatrix multiplication producing a column vector, then flattening to a 1D array. Here, each row of the grades matrix is multiplied by the weights vector to produce a single average score per student.\n\n\n\n# Example: equal-weight average across exams (axis=1 → per student)\navg_scores_axis = grades_matrix.mean(axis=1)\nprint(\"Average score per student (axis=1):\", [f\"{x:.2f}\" for x in avg_scores_axis])\n\nAverage score per student (axis=1): ['86.33', '81.33', '90.00', '73.33', '88.00']\n\n# Example: average score per exam (axis=0 → per exam)\navg_scores_exam = grades_matrix.mean(axis=0)\nprint(\"Average score per exam (axis=0):\", [f\"{x:.2f}\" for x in avg_scores_exam])\n\nAverage score per exam (axis=0): ['82.60', '85.40', '83.40']\n\n# Using matrix multiplication to compute averages\nn_exams = grades_matrix.shape[1]\nweights = np.ones((n_exams, 1)) / n_exams  # shape: (n_exams, 1)\naverages_via_dot = np.dot(grades_matrix, weights).flatten()\nprint(\"\\nAverages via matrix multiplication:\",\n      [f\"{x:.2f}\" for x in averages_via_dot])\n\n\nAverages via matrix multiplication: ['86.33', '81.33', '90.00', '73.33', '88.00']\n\n# Weighted sum example: suppose exams have weights 0.5, 0.3, 0.2\nexam_weights = np.array([0.5, 0.3, 0.2]).reshape(-1, 1)  # shape: (n_exams, 1)\nweighted_scores = np.dot(grades_matrix, exam_weights).flatten()\nprint(\"\\nWeighted average per student:\",\n      [f\"{x:.2f}\" for x in weighted_scores])\n\n\nWeighted average per student: ['87.40', '80.60', '89.50', '73.40', '87.10']\n\n\n\n\n\nConcept:\n- A NumPy array is efficient for numerical operations but has no column or row labels — you must remember indexes yourself.\n- A pandas DataFrame wraps a NumPy array with labels (row and column names), allowing:\n\nEasier indexing by name (df[\"Math\"]) instead of position.\nMixed data types in one table (numbers, text, dates).\nBuilt-in data inspection methods (.head(), .info(), .describe()).\n\nKey point: Deep learning libraries often use NumPy arrays internally, but pandas is more convenient for data cleaning and exploration.\n\n# Our NumPy grades_matrix (from Section 3)\nprint(\"NumPy array:\\n\", grades_matrix)\n\nNumPy array:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\nprint(\"Shape:\", grades_matrix.shape)\n\nShape: (5, 3)\n\n# Convert to DataFrame with labels\nexam_names = [\"Exam 1\", \"Exam 2\", \"Exam 3\"]\nstudent_names = list(student_scores.keys())\ngrades_df = pd.DataFrame(grades_matrix, index=student_names, columns=exam_names)\n\nprint(\"\\nDataFrame:\\n\", grades_df)\n\n\nDataFrame:\n        Exam 1  Exam 2  Exam 3\nAlice      88      92      79\nBob        78      84      82\nCarol      90      85      95\nDave       72      78      70\nEve        85      88      91\n\n# Accessing data\nprint(\"\\nScore of Carol in Exam 2 (by labels):\", grades_df.loc[\"Carol\", \"Exam 2\"])\n\n\nScore of Carol in Exam 2 (by labels): 85\n\nprint(\"Score of Carol in Exam 2 (by position):\", grades_matrix[2, 1])\n\nScore of Carol in Exam 2 (by position): 85\n\n# Quick stats for each exam\nprint(\"\\nExam averages:\\n\", grades_df.mean().round(2))\n\n\nExam averages:\n Exam 1    82.6\nExam 2    85.4\nExam 3    83.4\ndtype: float64\n\n\n\n\n\n\nConcept:\nIn real projects, we often load datasets from CSV or Excel files.\nPandas DataFrames are perfect for this stage because they:\n\nRead files directly into a labeled table.\nMake it easy to explore and summarize the data.\nAllow quick selection of features (X) and target labels (y) for model training.\n\nWe’ll load a planar dataset with two numeric features (x_coord, y_coord) and a binary label (label).\n\n# Load into DataFrame\nraw_df = pd.read_csv(data_path_here)\n\n# Inspect\nprint(\"Shape:\", raw_df.shape)\n\nShape: (400, 3)\n\nprint(\"\\nFirst 5 rows:\\n\", raw_df.head())\n\n\nFirst 5 rows:\n     x_coord   y_coord  label\n0  1.204442  3.576114      0\n1  0.158710 -1.482171      0\n2  0.095247 -1.279955      0\n3  0.349178 -2.064380      0\n4  0.694150  2.889109      0\n\n# Separate features and target\nfeatures = [\"x_coord\", \"y_coord\"]\ntarget = \"label\"\n\nX = raw_df[features].copy()\ny = raw_df[target].copy()\n\nprint(\"\\nFeatures sample:\\n\", X.head())\n\n\nFeatures sample:\n     x_coord   y_coord\n0  1.204442  3.576114\n1  0.158710 -1.482171\n2  0.095247 -1.279955\n3  0.349178 -2.064380\n4  0.694150  2.889109\n\nprint(\"\\nLabels sample:\\n\", y.head())\n\n\nLabels sample:\n 0    0\n1    0\n2    0\n3    0\n4    0\nName: label, dtype: int64\n\n\n\n\nConcept:\nA scatter plot lets us see how the two features (x_coord, y_coord) relate to the class label.\nIf classes are not linearly separable, a simple logistic regression will likely underperform compared to a neural network.\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6, 5))\n\n# Bright, high-contrast colors\ncolors = {0: \"orange\", 1: \"teal\"}\n\n# Scatter plot\nfor label_value in sorted(y.unique()):\n    subset = X[y == label_value]\n    plt.scatter(\n        subset[\"x_coord\"], subset[\"y_coord\"],\n        c=colors[label_value],\n        edgecolor=\"k\",\n        s=50,\n        label=f\"Class {label_value}\"\n    )\n\nplt.xlabel(\"x_coord\")\nplt.ylabel(\"y_coord\")\nplt.title(\"Planar Dataset by Label\")\nplt.legend(title=\"Label\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nConcept:\nWe’ll train two models on the planar dataset:\n\nLogistic Regression — a single-layer model that produces a linear decision boundary.\nShallow Neural Network — one hidden layer that can model non-linear boundaries.\n\n\n\n\n\n\nThis comparison shows why neural networks can outperform linear models on complex patterns.\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\n\n# Logistic Regression model: single Dense layer\nlog_reg_model = Sequential([\n    Dense(1, activation='sigmoid', input_shape=(2,))\n])\nlog_reg_model.compile(optimizer=Adam(),\n                      loss='binary_crossentropy',\n                      metrics=['accuracy'])\nlog_reg_history = log_reg_model.fit(X, y, epochs=100, batch_size=32, verbose=0)\nlog_acc = log_reg_model.evaluate(X, y, verbose=0)[1]\n\n\nprint(f\"Logistic Regression Accuracy: {log_acc:.2f} \\n \")\n\nLogistic Regression Accuracy: 0.66 \n \n\n\n\n# Neural Network model: one hidden layer\nnn_model = Sequential([\n    Dense(10, activation='relu', input_shape=(2,)),\n    Dense(1, activation='sigmoid')\n])\nnn_model.compile(optimizer=Adam(),\n                 loss='binary_crossentropy',\n                 metrics=['accuracy'])\nnn_history = nn_model.fit(X, y, epochs=100, batch_size=32, verbose=0)\nnn_acc = nn_model.evaluate(X, y, verbose=0)[1]\n\nprint(f\"Neural Network Accuracy:     {nn_acc:.2f}\")\n\nNeural Network Accuracy:     0.62\n\n\n\nimport matplotlib.pyplot as plt\n\n# Extract loss values\nlog_loss = log_reg_history.history['loss']\nnn_loss = nn_history.history['loss']\n\n# Extract accuracy values\nlog_acc_hist = log_reg_history.history['accuracy']\nnn_acc_hist = nn_history.history['accuracy']\n\nepochs_range = range(1, len(log_loss) + 1)\n\nplt.figure(figsize=(12, 5))\n\n# Loss plot\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, log_loss, label='Logistic Regression', color='orange')\nplt.plot(epochs_range, nn_loss, label='Neural Network', color='teal')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend()\n\n# Accuracy plot\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, log_acc_hist, label='Logistic Regression', color='orange')\nplt.plot(epochs_range, nn_acc_hist, label='Neural Network', color='teal')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTo better understand how each model separates the two classes, we will define an auxiliary plotting function called plot_decision_boundary.\nThis function will: 1. Create a grid over the feature space. 2. Use the model to predict the class for each point in the grid. 3. Display the predicted regions as a colored background. 4. Overlay the actual data points on top.\nAfter defining this function, we will call it for both the logistic regression and neural network models to visually compare their decision boundaries.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_decision_boundary(model, X, y, title):\n    # Create a mesh grid over the feature space\n    x_min, x_max = X[\"x_coord\"].min() - 1, X[\"x_coord\"].max() + 1\n    y_min, y_max = X[\"y_coord\"].min() - 1, X[\"y_coord\"].max() + 1\n    xx, yy = np.meshgrid(\n        np.linspace(x_min, x_max, 300),\n        np.linspace(y_min, y_max, 300)\n    )\n    \n    # Predict over the grid\n    grid_points = np.c_[xx.ravel(), yy.ravel()]\n    Z = model.predict(grid_points, verbose=0)\n    Z = (Z &gt; 0.5).astype(int).reshape(xx.shape)\n\n    # Plot contour and points\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Oranges, alpha=0.3)\n    \n    colors = {0: \"orange\", 1: \"teal\"}\n    for label_value in sorted(y.unique()):\n        subset = X[y == label_value]\n        plt.scatter(\n            subset[\"x_coord\"], subset[\"y_coord\"],\n            c=colors[label_value],\n            edgecolor=\"k\",\n            s=50,\n            label=f\"Class {label_value}\"\n        )\n    plt.xlabel(\"x_coord\")\n    plt.ylabel(\"y_coord\")\n    plt.title(title)\n    plt.legend()\n\n\n# Plot for both models side by side\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplot_decision_boundary(log_reg_model, X, y, \"Logistic Regression Decision Boundary\")\n\nplt.subplot(1, 2, 2)\nplot_decision_boundary(nn_model, X, y, \"Neural Network Decision Boundary\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "topics/python_workshop/python_workshop.html#python-fundamentals",
    "href": "topics/python_workshop/python_workshop.html#python-fundamentals",
    "title": "Python for Deep Learning",
    "section": "",
    "text": "Get familiar with Python’s basic building blocks: variables, lists, dictionaries, control flow, and functions.\n\n\n\nLists and dictionaries\nif, for, and while statements\nWriting and calling functions\n\n\n\n\nConcept:\n- Lists are ordered collections. Each item has a position called an index (starting from 0).\n- You can get a single element using list[index] (e.g., scores[0] → first element).\n- You can get a slice using list[start:stop], which returns elements from start up to but not including stop.\n- Dictionaries store key–value pairs. You look up a value by its key (like a label).\n- You can add new keys or update existing ones using dict[key] = value.\n- Keys must be unique; values can be any data type.\n\n# A list of exam scores for Alice\nscores_alice = [88, 92, 79]\n\n# Indexing: position 0 is the first score\nprint(\"First score:\", scores_alice[0])\n\nFirst score: 88\n\n# Slicing: [:2] means start at index 0, stop before index 2 → positions 0 and 1\nprint(\"First two scores:\", scores_alice[:2])\n\nFirst two scores: [88, 92]\n\n# A dictionary mapping student names to their list of scores\nstudent_scores = {\n    \"Alice\": [88, 92, 79],\n    \"Bob\":   [75, 83, 80],\n    \"Carol\": [90, 85, 95],\n    \"Dave\":  [72, 78, 70],\n}\n\n# Lookup: use the key (student's name) to get the list of scores\nprint(\"Carol's scores:\", student_scores[\"Carol\"])\n\nCarol's scores: [90, 85, 95]\n\n# Add a new student by assigning to a new key\nstudent_scores[\"Eve\"] = [85, 88, 91]\n\n# Update an existing student's scores (overwrites the old list)\nstudent_scores[\"Bob\"] = [78, 84, 82]\n\n# Get all keys (student names) and values (lists of scores)\nprint(\"Students:\", list(student_scores.keys()))\n\nStudents: ['Alice', 'Bob', 'Carol', 'Dave', 'Eve']\n\nprint(\"Sample scores:\", list(student_scores.values())[:2])  # [:2] → first two values\n\nSample scores: [[88, 92, 79], [78, 84, 82]]\n\n\n\n\n\nConcept:\n- if / elif / else lets the program choose actions based on conditions.\n- for loops iterate over items in a collection, letting you process each element in turn.\nWe’ll use the student_scores dictionary from the previous section.\n\n# Example 1: if / elif / else\nx = 87\nif x &gt;= 90:\n    grade = \"A\"\nelif x &gt;= 80:\n    grade = \"B\"\nelse:\n    grade = \"C or below\"\nprint(\"Grade bucket:\", grade)\n\nGrade bucket: B\n\n# Example 2: for loop over a student's scores\n# Reusing the student_scores dictionary from earlier\nscores_alice = student_scores[\"Alice\"]  # a list of Alice's scores\ntotal = 0\nfor s in scores_alice:\n    total = total + s\naverage = total / len(scores_alice)\nprint(\"Alice's average score:\", average)\n\nAlice's average score: 86.33333333333333\n\n\n\n\n\nConcept:\n- A function is a reusable block of code that takes inputs (parameters) and can return an output.\n- Use def function_name(parameters): to define it.\n- Use return to send a result back to the caller.\n- You can reuse loops and calculations inside a function so you don’t repeat the same code.\n\ndef average_score(scores):\n    \"\"\"\n    Calculate the average from a list of scores.\n    \"\"\"\n    total = 0\n    for s in scores:\n        total = total + s\n    return total / len(scores)\n\n# Example: Calculate averages for all students\nfor name in student_scores:  # loops over keys (student names)\n    avg = average_score(student_scores[name])\n    print(f\"{name}: {avg:.2f}\")\n\nAlice: 86.33\nBob: 81.33\nCarol: 90.00\nDave: 73.33\nEve: 88.00"
  },
  {
    "objectID": "topics/python_workshop/python_workshop.html#numerical-computing-with-numpy",
    "href": "topics/python_workshop/python_workshop.html#numerical-computing-with-numpy",
    "title": "Python for Deep Learning",
    "section": "",
    "text": "Concept:\nNumPy arrays are like lists but optimized for fast mathematical operations.\n- 1D array → like a row of numbers.\n- 2D array → like a table (rows × columns).\n- .shape tells you the size of the array.\n\n# 1D array: vector of exam scores\nscores_1d = np.array([88, 92, 79])\nprint(\"1D array:\", scores_1d)\n\n1D array: [88 92 79]\n\nprint(\"Shape:\", scores_1d.shape)  # (3,) → 3 elements in 1 dimension\n\nShape: (3,)\n\n# 2D array: scores for two students across three exams\nscores_2d = np.array([\n    [88, 92, 79],  # student 1\n    [75, 83, 80]   # student 2\n])\nprint(\"\\n2D array:\\n\", scores_2d)\n\n\n2D array:\n [[88 92 79]\n [75 83 80]]\n\nprint(\"Shape:\", scores_2d.shape)  # (2, 3) → 2 rows, 3 columns\n\nShape: (2, 3)\n\n# Now convert student_scores dictionary values into a 2D array\ngrades_matrix = np.array(list(student_scores.values()))\nprint(\"\\nGrades matrix:\\n\", grades_matrix)\n\n\nGrades matrix:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\nprint(\"Shape:\", grades_matrix.shape)  # rows = students, columns = exams\n\nShape: (5, 3)\n\n\n\n\nConcept:\n- Indexing works like Python lists: array[row_index, col_index] (0-based).\n- Slicing lets you select a range: start:stop returns elements from start up to (but not including) stop.\n- You can slice rows, columns, or both.\n\n# Example array for reference\nprint(\"Grades matrix:\\n\", grades_matrix)\n\nGrades matrix:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\n# Get the score of the first student in the first exam\nprint(\"\\nFirst student's first exam score:\", grades_matrix[0, 0])\n\n\nFirst student's first exam score: 88\n\n# Get all exam scores for the second student (row index 1)\nprint(\"Second student's scores:\", grades_matrix[1, :])\n\nSecond student's scores: [78 84 82]\n\n# Get all scores for the third exam (column index 2)\nprint(\"Scores in third exam:\", grades_matrix[:, 2])\n\nScores in third exam: [79 82 95 70 91]\n\n# Slice: first two students' scores\nprint(\"First two students' scores:\\n\", grades_matrix[0:2, :])\n\nFirst two students' scores:\n [[88 92 79]\n [78 84 82]]\n\n# Slice: first two exams for all students\nprint(\"First two exams for all students:\\n\", grades_matrix[:, 0:2])\n\nFirst two exams for all students:\n [[88 92]\n [78 84]\n [90 85]\n [72 78]\n [85 88]]\n\n\n\n\n\nConcept:\n- Element-wise operations apply a calculation to each element of an array.\n- Broadcasting lets NumPy apply operations between arrays of different shapes by “stretching” one to match the other (without copying data).\n- This is much faster and cleaner than using Python loops.\n\n# Add 5 points to every score (element-wise addition)\nprint(\"Original:\\n\", grades_matrix)\n\nOriginal:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\nprint(\"\\n+5 to every score:\\n\", grades_matrix + 5)\n\n\n+5 to every score:\n [[ 93  97  84]\n [ 83  89  87]\n [ 95  90 100]\n [ 77  83  75]\n [ 90  93  96]]\n\n# Multiply all scores by 1.1 to simulate a 10% bonus\nprint(\"\\n10% bonus:\\n\", grades_matrix * 1.1)\n\n\n10% bonus:\n [[ 96.8 101.2  86.9]\n [ 85.8  92.4  90.2]\n [ 99.   93.5 104.5]\n [ 79.2  85.8  77. ]\n [ 93.5  96.8 100.1]]\n\n# Broadcasting: subtract the minimum score in each column (exam) from that column\nmin_scores_per_exam = grades_matrix.min(axis=0)  # shape: (n_exams,)\nprint(\"\\nMinimum scores per exam:\", min_scores_per_exam)\n\n\nMinimum scores per exam: [72 78 70]\n\nadjusted = grades_matrix - min_scores_per_exam  # broadcasting happens here\nprint(\"\\nScores adjusted by exam minimum:\\n\", adjusted)\n\n\nScores adjusted by exam minimum:\n [[16 14  9]\n [ 6  6 12]\n [18  7 25]\n [ 0  0  0]\n [13 10 21]]\n\n\n\n\n\nConcept:\n- Matrix multiplication (np.dot) combines rows and columns, often used in deep learning layers to combine inputs with weights.\n- Axis-based operations let you apply functions (mean, sum, etc.) across rows or columns:\n\naxis=0 → operate down columns (across rows)\naxis=1 → operate across columns (per row)\n\nExtra notes: - np.ones(shape) creates an array of ones with the given shape.\n- Here we use it for equal weights when averaging scores: each exam gets the same weight.\n- .flatten() converts a multi-dimensional array into a 1D array.\n- After matrix multiplication, the result might be shape (n_students, 1); flattening makes it easier to print and work with.\n\n\n\nMatrix multiplication producing a column vector, then flattening to a 1D array. Here, each row of the grades matrix is multiplied by the weights vector to produce a single average score per student.\n\n\n\n# Example: equal-weight average across exams (axis=1 → per student)\navg_scores_axis = grades_matrix.mean(axis=1)\nprint(\"Average score per student (axis=1):\", [f\"{x:.2f}\" for x in avg_scores_axis])\n\nAverage score per student (axis=1): ['86.33', '81.33', '90.00', '73.33', '88.00']\n\n# Example: average score per exam (axis=0 → per exam)\navg_scores_exam = grades_matrix.mean(axis=0)\nprint(\"Average score per exam (axis=0):\", [f\"{x:.2f}\" for x in avg_scores_exam])\n\nAverage score per exam (axis=0): ['82.60', '85.40', '83.40']\n\n# Using matrix multiplication to compute averages\nn_exams = grades_matrix.shape[1]\nweights = np.ones((n_exams, 1)) / n_exams  # shape: (n_exams, 1)\naverages_via_dot = np.dot(grades_matrix, weights).flatten()\nprint(\"\\nAverages via matrix multiplication:\",\n      [f\"{x:.2f}\" for x in averages_via_dot])\n\n\nAverages via matrix multiplication: ['86.33', '81.33', '90.00', '73.33', '88.00']\n\n# Weighted sum example: suppose exams have weights 0.5, 0.3, 0.2\nexam_weights = np.array([0.5, 0.3, 0.2]).reshape(-1, 1)  # shape: (n_exams, 1)\nweighted_scores = np.dot(grades_matrix, exam_weights).flatten()\nprint(\"\\nWeighted average per student:\",\n      [f\"{x:.2f}\" for x in weighted_scores])\n\n\nWeighted average per student: ['87.40', '80.60', '89.50', '73.40', '87.10']\n\n\n\n\n\nConcept:\n- A NumPy array is efficient for numerical operations but has no column or row labels — you must remember indexes yourself.\n- A pandas DataFrame wraps a NumPy array with labels (row and column names), allowing:\n\nEasier indexing by name (df[\"Math\"]) instead of position.\nMixed data types in one table (numbers, text, dates).\nBuilt-in data inspection methods (.head(), .info(), .describe()).\n\nKey point: Deep learning libraries often use NumPy arrays internally, but pandas is more convenient for data cleaning and exploration.\n\n# Our NumPy grades_matrix (from Section 3)\nprint(\"NumPy array:\\n\", grades_matrix)\n\nNumPy array:\n [[88 92 79]\n [78 84 82]\n [90 85 95]\n [72 78 70]\n [85 88 91]]\n\nprint(\"Shape:\", grades_matrix.shape)\n\nShape: (5, 3)\n\n# Convert to DataFrame with labels\nexam_names = [\"Exam 1\", \"Exam 2\", \"Exam 3\"]\nstudent_names = list(student_scores.keys())\ngrades_df = pd.DataFrame(grades_matrix, index=student_names, columns=exam_names)\n\nprint(\"\\nDataFrame:\\n\", grades_df)\n\n\nDataFrame:\n        Exam 1  Exam 2  Exam 3\nAlice      88      92      79\nBob        78      84      82\nCarol      90      85      95\nDave       72      78      70\nEve        85      88      91\n\n# Accessing data\nprint(\"\\nScore of Carol in Exam 2 (by labels):\", grades_df.loc[\"Carol\", \"Exam 2\"])\n\n\nScore of Carol in Exam 2 (by labels): 85\n\nprint(\"Score of Carol in Exam 2 (by position):\", grades_matrix[2, 1])\n\nScore of Carol in Exam 2 (by position): 85\n\n# Quick stats for each exam\nprint(\"\\nExam averages:\\n\", grades_df.mean().round(2))\n\n\nExam averages:\n Exam 1    82.6\nExam 2    85.4\nExam 3    83.4\ndtype: float64"
  },
  {
    "objectID": "topics/python_workshop/python_workshop.html#working-with-data",
    "href": "topics/python_workshop/python_workshop.html#working-with-data",
    "title": "Python for Deep Learning",
    "section": "",
    "text": "Concept:\nIn real projects, we often load datasets from CSV or Excel files.\nPandas DataFrames are perfect for this stage because they:\n\nRead files directly into a labeled table.\nMake it easy to explore and summarize the data.\nAllow quick selection of features (X) and target labels (y) for model training.\n\nWe’ll load a planar dataset with two numeric features (x_coord, y_coord) and a binary label (label).\n\n# Load into DataFrame\nraw_df = pd.read_csv(data_path_here)\n\n# Inspect\nprint(\"Shape:\", raw_df.shape)\n\nShape: (400, 3)\n\nprint(\"\\nFirst 5 rows:\\n\", raw_df.head())\n\n\nFirst 5 rows:\n     x_coord   y_coord  label\n0  1.204442  3.576114      0\n1  0.158710 -1.482171      0\n2  0.095247 -1.279955      0\n3  0.349178 -2.064380      0\n4  0.694150  2.889109      0\n\n# Separate features and target\nfeatures = [\"x_coord\", \"y_coord\"]\ntarget = \"label\"\n\nX = raw_df[features].copy()\ny = raw_df[target].copy()\n\nprint(\"\\nFeatures sample:\\n\", X.head())\n\n\nFeatures sample:\n     x_coord   y_coord\n0  1.204442  3.576114\n1  0.158710 -1.482171\n2  0.095247 -1.279955\n3  0.349178 -2.064380\n4  0.694150  2.889109\n\nprint(\"\\nLabels sample:\\n\", y.head())\n\n\nLabels sample:\n 0    0\n1    0\n2    0\n3    0\n4    0\nName: label, dtype: int64\n\n\n\n\nConcept:\nA scatter plot lets us see how the two features (x_coord, y_coord) relate to the class label.\nIf classes are not linearly separable, a simple logistic regression will likely underperform compared to a neural network.\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6, 5))\n\n# Bright, high-contrast colors\ncolors = {0: \"orange\", 1: \"teal\"}\n\n# Scatter plot\nfor label_value in sorted(y.unique()):\n    subset = X[y == label_value]\n    plt.scatter(\n        subset[\"x_coord\"], subset[\"y_coord\"],\n        c=colors[label_value],\n        edgecolor=\"k\",\n        s=50,\n        label=f\"Class {label_value}\"\n    )\n\nplt.xlabel(\"x_coord\")\nplt.ylabel(\"y_coord\")\nplt.title(\"Planar Dataset by Label\")\nplt.legend(title=\"Label\")\nplt.show()"
  },
  {
    "objectID": "topics/python_workshop/python_workshop.html#logistic-regression-vs-neural-network",
    "href": "topics/python_workshop/python_workshop.html#logistic-regression-vs-neural-network",
    "title": "Python for Deep Learning",
    "section": "",
    "text": "Concept:\nWe’ll train two models on the planar dataset:\n\nLogistic Regression — a single-layer model that produces a linear decision boundary.\nShallow Neural Network — one hidden layer that can model non-linear boundaries.\n\n\n\n\n\n\nThis comparison shows why neural networks can outperform linear models on complex patterns.\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\n\n# Logistic Regression model: single Dense layer\nlog_reg_model = Sequential([\n    Dense(1, activation='sigmoid', input_shape=(2,))\n])\nlog_reg_model.compile(optimizer=Adam(),\n                      loss='binary_crossentropy',\n                      metrics=['accuracy'])\nlog_reg_history = log_reg_model.fit(X, y, epochs=100, batch_size=32, verbose=0)\nlog_acc = log_reg_model.evaluate(X, y, verbose=0)[1]\n\n\nprint(f\"Logistic Regression Accuracy: {log_acc:.2f} \\n \")\n\nLogistic Regression Accuracy: 0.66 \n \n\n\n\n# Neural Network model: one hidden layer\nnn_model = Sequential([\n    Dense(10, activation='relu', input_shape=(2,)),\n    Dense(1, activation='sigmoid')\n])\nnn_model.compile(optimizer=Adam(),\n                 loss='binary_crossentropy',\n                 metrics=['accuracy'])\nnn_history = nn_model.fit(X, y, epochs=100, batch_size=32, verbose=0)\nnn_acc = nn_model.evaluate(X, y, verbose=0)[1]\n\nprint(f\"Neural Network Accuracy:     {nn_acc:.2f}\")\n\nNeural Network Accuracy:     0.62\n\n\n\nimport matplotlib.pyplot as plt\n\n# Extract loss values\nlog_loss = log_reg_history.history['loss']\nnn_loss = nn_history.history['loss']\n\n# Extract accuracy values\nlog_acc_hist = log_reg_history.history['accuracy']\nnn_acc_hist = nn_history.history['accuracy']\n\nepochs_range = range(1, len(log_loss) + 1)\n\nplt.figure(figsize=(12, 5))\n\n# Loss plot\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, log_loss, label='Logistic Regression', color='orange')\nplt.plot(epochs_range, nn_loss, label='Neural Network', color='teal')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend()\n\n# Accuracy plot\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, log_acc_hist, label='Logistic Regression', color='orange')\nplt.plot(epochs_range, nn_acc_hist, label='Neural Network', color='teal')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTo better understand how each model separates the two classes, we will define an auxiliary plotting function called plot_decision_boundary.\nThis function will: 1. Create a grid over the feature space. 2. Use the model to predict the class for each point in the grid. 3. Display the predicted regions as a colored background. 4. Overlay the actual data points on top.\nAfter defining this function, we will call it for both the logistic regression and neural network models to visually compare their decision boundaries.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_decision_boundary(model, X, y, title):\n    # Create a mesh grid over the feature space\n    x_min, x_max = X[\"x_coord\"].min() - 1, X[\"x_coord\"].max() + 1\n    y_min, y_max = X[\"y_coord\"].min() - 1, X[\"y_coord\"].max() + 1\n    xx, yy = np.meshgrid(\n        np.linspace(x_min, x_max, 300),\n        np.linspace(y_min, y_max, 300)\n    )\n    \n    # Predict over the grid\n    grid_points = np.c_[xx.ravel(), yy.ravel()]\n    Z = model.predict(grid_points, verbose=0)\n    Z = (Z &gt; 0.5).astype(int).reshape(xx.shape)\n\n    # Plot contour and points\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Oranges, alpha=0.3)\n    \n    colors = {0: \"orange\", 1: \"teal\"}\n    for label_value in sorted(y.unique()):\n        subset = X[y == label_value]\n        plt.scatter(\n            subset[\"x_coord\"], subset[\"y_coord\"],\n            c=colors[label_value],\n            edgecolor=\"k\",\n            s=50,\n            label=f\"Class {label_value}\"\n        )\n    plt.xlabel(\"x_coord\")\n    plt.ylabel(\"y_coord\")\n    plt.title(title)\n    plt.legend()\n\n\n# Plot for both models side by side\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplot_decision_boundary(log_reg_model, X, y, \"Logistic Regression Decision Boundary\")\n\nplt.subplot(1, 2, 2)\nplot_decision_boundary(nn_model, X, y, \"Neural Network Decision Boundary\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "topics/multi_layer/multi_layer_credit_score.html",
    "href": "topics/multi_layer/multi_layer_credit_score.html",
    "title": "Multi layer Neural Network for Credit Score classification",
    "section": "",
    "text": "In this tutorial we’ll build and evaluate a multi-layer neural network (MLP) to predict credit default risk (SeriousDlqin2yrs, binary 0/1).\nWe will:\n\nSplit the data with stratification to keep the class balance.\nStandardize numeric features (important for MLP stability).\nDefine a small MLP using ReLU hidden layers and a sigmoid output.\nTrain with binary cross-entropy and report accuracy, AUC, precision, recall, and F1.\nDiscuss practical knobs: epochs, batch size, and early stopping.\n\n\n\n\nHidden layers: ReLU activations learn non-linear decision boundaries efficiently.\n\nOutput layer: Sigmoid maps predictions to probabilities in ([0,1]) for binary classification.\n\nLoss: Binary cross-entropy aligns with Bernoulli likelihood and probabilistic outputs.\n\nMetrics: Accuracy can be misleading with imbalance; AUC, precision, recall, F1 add nuance.\n\n\n\n\n\nTarget: SeriousDlqin2yrs — whether serious delinquency occurred within 2 years (0/1).\nFeatures: 10 standardized numeric predictors (after cleaning and dropping the ID column).\n\n\n\nShow the code\n# Core data handling\nimport os                           # file paths\nimport numpy as np                  # numeric arrays, vectorized ops\nimport pandas as pd                 # dataframes, CSV I/O\n\n# Model selection & preprocessing\nfrom sklearn.model_selection import train_test_split   # train/test split with stratify\nfrom sklearn.preprocessing import StandardScaler       # feature standardization (fit on train only!)\n\n# Deep learning (Keras/TensorFlow)\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential                # simple stack model\nfrom tensorflow.keras.layers import Dense, Input       # fully connected layers\nfrom tensorflow.keras import metrics                   # ready-made metrics: AUC, Precision, Recall, F1",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/multi_layer/multi_layer_credit_score.html#overview",
    "href": "topics/multi_layer/multi_layer_credit_score.html#overview",
    "title": "Multi layer Neural Network for Credit Score classification",
    "section": "",
    "text": "In this tutorial we’ll build and evaluate a multi-layer neural network (MLP) to predict credit default risk (SeriousDlqin2yrs, binary 0/1).\nWe will:\n\nSplit the data with stratification to keep the class balance.\nStandardize numeric features (important for MLP stability).\nDefine a small MLP using ReLU hidden layers and a sigmoid output.\nTrain with binary cross-entropy and report accuracy, AUC, precision, recall, and F1.\nDiscuss practical knobs: epochs, batch size, and early stopping.\n\n\n\n\nHidden layers: ReLU activations learn non-linear decision boundaries efficiently.\n\nOutput layer: Sigmoid maps predictions to probabilities in ([0,1]) for binary classification.\n\nLoss: Binary cross-entropy aligns with Bernoulli likelihood and probabilistic outputs.\n\nMetrics: Accuracy can be misleading with imbalance; AUC, precision, recall, F1 add nuance.\n\n\n\n\n\nTarget: SeriousDlqin2yrs — whether serious delinquency occurred within 2 years (0/1).\nFeatures: 10 standardized numeric predictors (after cleaning and dropping the ID column).\n\n\n\nShow the code\n# Core data handling\nimport os                           # file paths\nimport numpy as np                  # numeric arrays, vectorized ops\nimport pandas as pd                 # dataframes, CSV I/O\n\n# Model selection & preprocessing\nfrom sklearn.model_selection import train_test_split   # train/test split with stratify\nfrom sklearn.preprocessing import StandardScaler       # feature standardization (fit on train only!)\n\n# Deep learning (Keras/TensorFlow)\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential                # simple stack model\nfrom tensorflow.keras.layers import Dense, Input       # fully connected layers\nfrom tensorflow.keras import metrics                   # ready-made metrics: AUC, Precision, Recall, F1",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/multi_layer/multi_layer_credit_score.html#data-preprocessing",
    "href": "topics/multi_layer/multi_layer_credit_score.html#data-preprocessing",
    "title": "Multi layer Neural Network for Credit Score classification",
    "section": "Data preprocessing",
    "text": "Data preprocessing\nBefore training, we need to prepare the dataset:\n\nRemove rows with missing values.\n\nSeparate features (X) from the target (y = SeriousDlqin2yrs).\n\nSplit into training and test sets (keeping class balance with stratify).\n\nStandardize features so each has mean 0 and variance 1 — this helps the neural net train smoothly.\n\n\n\nShow the code\ndef preprocess_data(df):\n    \"\"\"\n    Clean, split, and scale the dataset for classification.\n    \"\"\"\n    # 1) Remove rows with missing values\n    df = df.dropna()\n\n    # 2) Separate features and target\n    X = df.drop(\"SeriousDlqin2yrs\", axis=1)\n    y = df[\"SeriousDlqin2yrs\"]\n\n    # 3) Train/test split with stratification to preserve class ratio\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.3, random_state=42, stratify=y\n    )\n\n    # 4) Standardize features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled  = scaler.transform(X_test)\n\n    return X_train_scaled, X_test_scaled, y_train, y_test\n\n\n\n\nShow the code\n# Path to the dataset (inside Documents/BOI_DL_website/data)\ndata_path = os.path.join(\n    os.path.expanduser(\"~\\\\Documents\\\\BOI_DL_website\"),\n    \"data\\\\credit_data.csv\"\n)\n\n# Load raw dataset\nraw_df = pd.read_csv(data_path)\n\n# Apply preprocessing: clean → split → scale\nX_train, X_test, y_train, y_test = preprocess_data(raw_df)",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/multi_layer/multi_layer_credit_score.html#model-architecture-training-setup",
    "href": "topics/multi_layer/multi_layer_credit_score.html#model-architecture-training-setup",
    "title": "Multi layer Neural Network for Credit Score classification",
    "section": "Model architecture & training setup",
    "text": "Model architecture & training setup\nWe’ll build a small MLP (multi-layer perceptron):\n\nInput (10 features): matches the scaled columns produced in preprocessing.\n\nHidden layers: Dense(60, ReLU) → Dense(5, ReLU)\n\nReLU speeds up training and handles nonlinearity well.\n\nWidth 60 then 5 is a compact architecture suitable for tabular credit data.\n\nOutput: Dense(1, Sigmoid) gives a probability for the positive class.\nLoss: binary_crossentropy (standard for binary classification).\n\nOptimizer: Adam with learning rate 1e-3 (robust default).\n\nMetrics: accuracy + AUC, precision, recall, F1 for a fuller picture on imbalanced data.\nTraining: 25 epochs, batch size 32.\n\nInstead of updating weights after every single example (which would be noisy and slow) or after the entire dataset (which would be memory-heavy and inefficient), we train in mini-batches:\n\nEach epoch, the training data is split into groups of 32 samples (mini-batches).\n\nFor each mini-batch, the model computes predictions, calculates loss, and performs a weight update.\n\nThis balances stability (less noisy than 1-sample updates) with efficiency (faster than full-dataset updates).\n\n\n\n\nThe multi-layer neural network used in this tutorial. It takes 10 standardized input features, passes them through two hidden layers (60 and 5 neurons with ReLU activations), and produces a single sigmoid output that represents the probability of default.\n\n\n\n\nShow the code\n# Define a simple feed-forward network for binary classification\nmodel = Sequential([\n    Input(shape=(10,)),                                   # Input vector of length 10 (scaled features)\n    Dense(60, activation=\"relu\", kernel_initializer=\"uniform\"),  # Hidden layer 1: 60 units + ReLU\n    Dense(5,  activation=\"relu\", kernel_initializer=\"uniform\"),  # Hidden layer 2: 5 units + ReLU\n    Dense(1,  activation=\"sigmoid\")                              # Output: probability of positive class\n])\n\n# Compile with binary cross-entropy and a useful metric set for imbalance\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-3),             # Adam with lr=0.001\n    loss=\"binary_crossentropy\",                           # Suitable for sigmoid output\n    metrics=[\n        \"accuracy\",\n        metrics.AUC(name=\"auc\"),\n        metrics.Precision(name=\"precision\"),\n        metrics.Recall(name=\"recall\"),\n        metrics.F1Score(name=\"f1\")                        # Requires TF &gt;= 2.11\n    ]\n)\n\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    epochs=25,                        # training passes over the dataset\n    batch_size=32,                    # mini-batch size\n    # validation_split=0.2,           # (Optional) hold out 20% of train for validation curves\n    # callbacks=[es],                 # (Optional) add early stopping\n    verbose=0\n)",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/multi_layer/multi_layer_credit_score.html#model-evaluation",
    "href": "topics/multi_layer/multi_layer_credit_score.html#model-evaluation",
    "title": "Multi layer Neural Network for Credit Score classification",
    "section": "Model evaluation",
    "text": "Model evaluation\nAfter training, we test the model on the held-out test set.\nThe evaluate function returns the loss and all metrics we specified in compile (accuracy, AUC, precision, recall, F1).\nPresenting them in a clean, rounded format makes the results easier to interpret.\n\n\nShow the code\n# Evaluate on the test set and return metrics as a dictionary\ntest_metrics = model.evaluate(X_test, y_test, verbose=0, return_dict=True)\n\n# Format nicely: metric name + rounded value\nfor key, value in test_metrics.items():\n    print(f\"{key:&lt;10}: {value:.2f}\")\n\n\naccuracy  : 0.93\nauc       : 0.82\nf1        : 0.13\nloss      : 0.20\nprecision : 0.56\nrecall    : 0.16",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/multi_layer/multi_layer_credit_score.html#training-history",
    "href": "topics/multi_layer/multi_layer_credit_score.html#training-history",
    "title": "Multi layer Neural Network for Credit Score classification",
    "section": "Training history",
    "text": "Training history\nLooking at metrics across epochs helps us understand model behavior:\n\nLoss curve: should generally decrease; if it rises again, the model may be overfitting.\n\nAccuracy / AUC curves: should increase and stabilize.\n\nPrecision/recall tradeoff: sometimes one rises while the other falls; looking at both is important.\n\nPlotting the training history gives a clear picture of how the network improves during training.\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\n# Convert training history to a DataFrame for easy plotting\nhistory_df = pd.DataFrame(history.history)\n\n# Plot loss\nplt.figure(figsize=(6,4))\nplt.plot(history_df[\"loss\"], label=\"Training loss\")\nplt.title(\"Training loss over epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nShow the code\n# Plot accuracy and AUC\nplt.figure(figsize=(6,4))\nplt.plot(history_df[\"accuracy\"], label=\"Accuracy\")\nplt.plot(history_df[\"auc\"], label=\"AUC\")\nplt.title(\"Training metrics over epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Metric value\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/multi_layer/multi_layer_credit_score.html#appendix-metrics-formulas",
    "href": "topics/multi_layer/multi_layer_credit_score.html#appendix-metrics-formulas",
    "title": "Multi layer Neural Network for Credit Score classification",
    "section": "Appendix: Metrics & Formulas",
    "text": "Appendix: Metrics & Formulas\nThis page reports binary classification metrics computed on a held-out test set.\nLet TP, FP, TN, FN be counts from the confusion matrix at a threshold \\(t\\) (often \\(t=0.5\\)).\nLet \\(y_{i} \\in \\{0,1\\}\\) be the true label and \\(\\hat{p}_i \\in [0,1]\\) the model’s predicted probability for the positive class.\n\nBinary Cross-Entropy (Log Loss)\nMeasures the quality of probabilistic predictions (lower is better): \\[\n\\text{BCE} = -\\frac{1}{n}\\sum_{i=1}^{n}\\Big[y_i \\log(\\hat{p}_i) + (1-y_i)\\log\\big(1-\\hat{p}_i\\big)\\Big].\n\\]\n\nProper scoring rule: encourages calibrated probabilities.\nUsed as the training loss for the sigmoid output.\n\n\n\nAccuracy\nShare of correct predictions at threshold (t): \\[\n\\text{Accuracy} = \\frac{TP + TN}{TP + FP + TN + FN}.\n\\]\n\nCan be misleading under class imbalance.\n\n\n\nPrecision (Positive Predictive Value)\n“How many predicted positives are truly positive?”\n\\[\n\\text{Precision} = \\frac{TP}{TP + FP}.\n\\]\n\n\nRecall (Sensitivity, TPR)\n“How many actual positives did we catch?”\n\\[\n\\text{Recall} = \\frac{TP}{TP + FN}.\n\\]\n\n\nF1 Score\nHarmonic mean of precision and recall: \\[\n\\text{F1} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n= \\frac{2TP}{2TP + FP + FN}.\n\\]\n\nBalances miss rate (FN) vs. false alarms (FP).\nGeneralization: \\(F_\\beta\\) weights recall \\(\\beta\\) times more than precision:\n\n\\[\nF_\\beta = (1+\\beta^2)\\,\\frac{\\text{Precision}\\cdot\\text{Recall}}{(\\beta^2\\cdot\\text{Precision})+\\text{Recall}}.\n\\]\n\n\nAUC (ROC-AUC)\nThreshold-free measure of ranking quality (higher is better).\n- ROC curve: plot \\(\\text{TPR}=\\frac{TP}{TP+FN}\\) vs. \\(\\text{FPR}=\\frac{FP}{FP+TN}\\) as \\(t\\) varies.\n\nAUC is the area under the ROC curve and equals the probability a random positive is ranked above a random negative: \\[\n\\text{AUC} = \\Pr\\big(\\hat{p}^+ &gt; \\hat{p}^-\\big).\n\\]\n\n\n\nPractical Notes\n\nThreshold choice ((t)) trades precision vs. recall; tune (t) to business costs or by maximizing a metric (e.g., F1) on validation data.\nImbalanced data: rely less on accuracy; prefer AUC, PR curves, F1, and class-specific error analysis.\nCalibration: well-calibrated \\(\\hat{p}\\) improves decision-making when costs vary",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/exercises/exercise_1.html",
    "href": "topics/exercises/exercise_1.html",
    "title": "Neural Networks Workshop — Practice Exercise Set",
    "section": "",
    "text": "Overview\nIn this exercise, you will work with the credit_data dataset and progress step by step through a short exploratory data analysis, a logistic regression baseline, a single-layer neural network, and an optional multi-layer neural network. Each section builds on the previous one so you can follow the workflow without getting lost.\nThe target variable is:\n\nSeriousDlqin2yrs — whether the person experienced financial distress severe enough to be 90+ days delinquent within the next two years.\n\nAll remaining columns serve as predictors.\n\n\n\n1. Load and Inspect the Data\n\n1.1 Load the dataset\nLoad the CSV file into a DataFrame named credit_data.\n\n\n1.2 Inspect its structure\nView:\n\nthe first rows\n\nthe column types\n\nsummary statistics\n\nMake sure SeriousDlqin2yrs contains only 0 and 1.\n\n\n1.3 Identify target and predictors\nConfirm that the target is binary and all other columns are features used for modeling.\n\n\n\n\n2. Handle Missing Values\n\n2.1 Detect missingness\nCount missing values per column and identify which features require imputation.\n\n\n2.2 Choose an imputation strategy\nUse the median for numeric features and explain why this is appropriate for skewed financial data.\n\n\n2.3 Create a cleaned dataset\nApply the transformations and verify that no missing values remain.\n\n\n\n\n3. Exploratory Data Analysis (EDA)\nKeep this focused and practical.\n\n3.1 Examine the target distribution\nPlot the proportion of 0’s and 1’s to understand the level of class imbalance.\n\n\n3.2 Explore important numeric features\nLook at distributions (histograms or boxplots) of a few features such as:\n\nage\n\nDebtRatio\n\nMonthlyIncome\n\nDiscuss any unusual patterns or outliers.\n\n\n3.3 Correlation inspection\nCompute a correlation matrix and observe:\n\nwhich features correlate most strongly with the target\n\nwhich features correlate strongly with each other\n\n\n\n\n\n4. Train/Test Split\n\n4.1 Split the data\nCreate a stratified split such that the test set is 25% of the data.\n\n\n4.2 Scale the predictors\nStandardize the numeric predictors. Fit the scaling on the training data and apply it to both training and test sets.\n\n\n\n\n5. Logistic Regression Baseline\n\n5.1 Fit a logistic regression model\nUse the cleaned, scaled training data.\n\n\n5.2 Evaluate performance\nProduce:\n\naccuracy\n\nprecision\n\nrecall\n\nF1 score\n\nAUC\n\nconfusion matrix\n\n\n\n5.3 Interpret the results\nDiscuss at least one strength and one limitation of logistic regression in the context of this dataset.\n\n\n\n\n6. Single-Layer Neural Network\nYou will now build a shallow neural network with one hidden layer.\n\n6.1 Define the architecture\nUse: - one hidden layer with a small number of units\n- ReLU activation in the hidden layer\n- sigmoid activation in the output layer\n\n\n6.2 Compile the model\nUse binary cross-entropy loss, the Adam optimizer, and accuracy/AUC.\n\n\n6.3 Train the model\nTrain for about 20 epochs with a validation split.\nPlot the training and validation curves and look for signs of overfitting.\n\n\n6.4 Evaluate\nCompare performance to logistic regression using the same metrics.\n\n\n\n\n7. Optional: Multi-Layer Neural Network\nThis section is for students who want to explore deeper models.\n\n7.1 Build a deeper architecture\nUse two or more hidden layers (e.g. 32 → 16 → 1).\n\n\n7.2 Consider regularization\nTry dropout or L2 regularization to reduce overfitting.\n\n\n7.3 Train and compare\nEvaluate your deep model and compare it with: - logistic regression\n- single-layer network\n\n\n7.4 Discuss findings\nExplain whether depth helped or harmed performance and why.\n\n\n\n\n8. Summary Questions\nAnswer the following:\n\nWhich model achieved the highest AUC?\n\nWhich model showed signs of overfitting?\n\nIf you had to deploy one model, which would you choose and why?\n\nWhat additional preprocessing or feature engineering steps could improve model performance?\n\n\n\n\nEnd of Exercise Set\nWork through the tasks in order, verifying each step before moving to the next. This workflow mirrors a real-world modeling pipeline and prepares you for more advanced neural network structures."
  },
  {
    "objectID": "topics/cnn/convolution.html",
    "href": "topics/cnn/convolution.html",
    "title": "Convolutional Neural Network (CNN) for Image Classification",
    "section": "",
    "text": "Build, train, and evaluate a Convolutional Neural Network using the Sign Language MNIST dataset.\n\nImport and Load Data\n\nImport necessary libraries, including TensorFlow and Keras layers.\nLoad the training and test datasets from CSV files.\n\n\n\nShow the code\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n\n\nfrom tensorflow.keras import backend as K\n\n\nfrom tf_keras_vis.gradcam import Gradcam\nfrom tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\nfrom tf_keras_vis.utils.scores import CategoricalScore\nfrom tf_keras_vis.utils.model_modifiers import ReplaceToLinear\nfrom tf_keras_vis.utils import normalize\nfrom tf_keras_vis.saliency import Saliency\n\n\n\n\nShow the code\n\ntrain_set = pd.read_csv(os.path.join(os.path.expanduser(\"~\\\\Documents\\\\BOI_DL_website\"),\n\"data\\\\sign_mnist_train.csv\"))\n\ntest_set = pd.read_csv(os.path.join(os.path.expanduser(\"~\\\\Documents\\\\BOI_DL_website\"),\n\"data\\\\sign_mnist_test.csv\"))\n\n\n\n\nPreprocessing Labels\n\nThe Sign Language MNIST dataset contains labels for letters A–Z, but the letter J has no images.\nBecause of this, the dataset’s labels skip the index 9.\nTo make the labels continuous (0–23), we:\n\nKeep labels 0–8 as they are.\nSubtract 1 from all labels ≥ 10.\n\nThen we apply one-hot encoding to obtain 24 output classes.\nA helper function (reverse_remap) converts predictions back to the original A–Z index range when needed.\n\n\n\nShow the code\n\ndef preprocess_data(df, img_height=28, img_width=28):\n  \n  processed_df = df / 255.0\n\n  processed_df = processed_df.values.reshape(-1, img_height, img_width, 1).copy()\n\n  return processed_df\n\n\ndef preprocess_labels(label_series, num_classes=24):\n    \"\"\"\n    Remaps labels to skip index 9 (J) and applies one-hot encoding.\n\n    Parameters:\n    - label_series: a pandas Series or 1D array of labels (originally 0–25, with 9 missing)\n    - num_classes: total number of actual classes (default 24)\n\n    Returns:\n    - One-hot encoded labels of shape (n_samples, num_classes)\n    \"\"\"\n    labels = np.array(label_series)\n\n    remapped_labels = np.array([l - 1 if l &gt; 9 else l for l in labels])\n\n    categorical_labels = to_categorical(remapped_labels, num_classes=num_classes)\n\n    return categorical_labels\n\n\n# Reverse the earlier remapping: add 1 to all labels ≥ 9\ndef reverse_remap(labels):\n    return [l + 1 if l &gt;= 9 else l for l in labels]\n\n\n\ndef show_predictions(x_data, y_true, y_pred, indices=None, n=6):\n    if indices is None:\n        indices = np.random.choice(len(x_data), n, replace=False)\n\n    plt.figure(figsize=(12, 6))\n    for i, idx in enumerate(indices):\n        plt.subplot(2, n // 2, i + 1)\n        plt.imshow(x_data[idx].reshape(28, 28), cmap='gray')\n        plt.title(f\"Pred: {y_pred[idx]}\\nTrue: {y_true[idx]}\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nShow the code\n\n\n# Separate labels\ny_train = preprocess_labels(train_set['label'])\n\ny_test = preprocess_labels(test_set['label'])\n\n# Remove labels from the pixel data\nx_train = preprocess_data(train_set.drop('label', axis=1))\n\nx_test = preprocess_data(test_set.drop('label', axis=1))\n\n\n\n\nDefine CNN Model\n\nBuild a Convolutional Neural Network using the Keras Functional API:\n\nAn input layer for images of shape (28, 28, 1).\nBlock 1: two Conv2D layers with 32 filters (3×3, ReLU, padding=‘same’), followed by a MaxPooling2D layer (2×2).\nBlock 2: two Conv2D layers with 64 filters (3×3, ReLU, padding=‘same’).\nBlock 3: two Conv2D layers with 128 filters (3×3, ReLU, padding=‘same’).\nA Flatten layer to convert feature maps into a vector.\nA Dense layer with 256 units and ReLU activation.\nA Dropout layer with rate 0.3 to reduce overfitting.\nA final Dense layer with 24 units and softmax activation for classification.\n\nCompile the model using the Adam optimizer and the categorical cross-entropy loss function.\n\n\n\nShow the code\n# Input\ninputs = Input(shape=(28, 28, 1))\n\n# Block 1\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n# Block 2\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n\n# Block 3\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n\n# Dense head\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.3)(x)\n\n# Output\noutputs = Dense(24, activation='softmax')(x)\n\n# Final model\nmodel = Model(inputs, outputs)\n\n# Compile\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\n\n\n\nTrain the Model\n\nFit the model on the training data for 5 epochs with batch size 128.\nUse the test data as validation during training.\n\n\n\nShow the code\n\nhistory = model.fit(\n    x_train, y_train,\n    validation_data=(x_test, y_test),\n    epochs=10,\n    batch_size=128,\n    verbose = 0\n)\n\n\n\n\nEvaluate the Model\n\nEvaluate the model on the test data.\nReport test accuracy.\n\n\n\nShow the code\nloss, accuracy = model.evaluate(x_test, y_test)\n\n\nShow the code\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\n\n\n\nVisualizing Model Decisions with Grad-CAM\nConvolutional Neural Networks can achieve high accuracy, but it is often unclear which parts of an image drive their predictions. To make the model more interpretable, we use visualization techniques such as Grad-CAM, Guided Backpropagation, and Guided Grad-CAM.\n\nGrad-CAM (Gradient-weighted Class Activation Mapping)\nHighlights the image regions that had the strongest influence on the model’s predicted class. It does this by examining the gradients flowing into the last convolutional layer, which contains spatial information.\nGuided Backpropagation\nComputes fine-grained pixel-level gradients that show which pixels most strongly support the predicted class. The result is a high-resolution saliency map.\nGuided Grad-CAM\nCombines the coarse, region-level information from Grad-CAM with the fine details from Guided Backpropagation.\nThe result is a high-resolution heatmap that highlights exactly which parts of the image contributed to the model’s decision.\n\nBelow, we apply all three methods to a selected test image to see what the model focused on when predicting the hand sign.\nThe figure below shows four visualizations side by side:\n\nOriginal Image – the input image given to the model.\nGrad-CAM – a coarse heatmap showing which regions of the image contributed most to the model’s prediction.\nGuided Backpropagation – a fine-grained gradient map showing which pixels support the predicted class.\nGuided Grad-CAM – an overlay combining Grad-CAM with Guided Backprop to produce a high-resolution explanation.\n\n\n\nShow the code\n# Choose which test image to analyze\nidx = 3\nimage = x_test[idx:idx+1]  # shape (1, 28, 28, 1)\n\n\nfor layer in reversed(model.layers):\n    if isinstance(layer, tf.keras.layers.Conv2D):\n        last_conv_layer_name = layer.name\n        break\n\n\n# ---- 1. Predict class ----\npred_probs = model.predict(image, verbose=0)[0]\npred_index = np.argmax(pred_probs)\nprint(\"Predicted class:\", pred_index)\n\n\nPredicted class: 0\n\n\nShow the code\n# ---- 2. Grad-CAM ----\nscore = CategoricalScore(pred_index)\n\ngradcam = Gradcam(\n    model,\n    model_modifier=None,\n    clone=True\n)\n\ncam = gradcam(\n    score,\n    image,\n    penultimate_layer=last_conv_layer_name\n)\nheatmap = cam[0]   # remove batch dimension\n\n\n\ndef model_modifier(m):\n    # Replace the final softmax activation with linear\n    m.layers[-1].activation = tf.keras.activations.linear\n\n\n# ---- 3. Guided Backprop ----\nsaliency = Saliency(\n    model,\n    model_modifier=model_modifier,\n    clone=True\n)\n\ngbp = saliency(score, image)   # guided backprop gradients, shape (1, 28, 28, N)\n\n\nC:\\Users\\internet\\AppData\\Local\\Programs\\Python\\PYTHON~2\\Lib\\site-packages\\keras\\src\\models\\functional.py:241: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: keras_tensor\nReceived: inputs=['Tensor(shape=(1, 28, 28, 1))']\n  warnings.warn(msg)\n\n\nShow the code\ngbp = gbp[0]                   # remove batch dimension → shape (28, 28, N)\ngbp = normalize(gbp)           # rescale 0–1\n\n\n\n# ---- 4. Guided Grad-CAM (Grad-CAM × Guided Backprop) ----\nguided_gradcam = gbp * heatmap\n\n\n\n\nShow the code\n# Normalize Grad-CAM heatmap to 0–1 for display\nheatmap_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n\n# Convert Guided Backprop to a single-channel saliency map\ngbp_gray = normalize(gbp)\n\nplt.figure(figsize=(13, 4))\n\n# Original\nplt.subplot(1, 4, 1)\nplt.title(\"Original\")\nplt.imshow(image[0].reshape(28, 28), cmap='gray')\nplt.axis('off')\n\n\n(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))\n\n\nShow the code\n# Grad-CAM\nplt.subplot(1, 4, 2)\nplt.title(\"Grad-CAM\")\nplt.imshow(heatmap_norm, cmap='jet')\nplt.axis('off')\n\n\n(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))\n\n\nShow the code\n# Guided Backprop\nplt.subplot(1, 4, 3)\nplt.title(\"Guided Backprop\")\nplt.imshow(gbp_gray, cmap='gray')\nplt.axis('off')\n\n\n(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))\n\n\nShow the code\n# Guided Grad-CAM\nplt.subplot(1, 4, 4)\nplt.title(\"Guided Grad-CAM\")\nplt.imshow(image[0].reshape(28, 28), cmap='gray')\nplt.imshow(heatmap_norm, cmap='jet', alpha=0.45)\nplt.axis('off')\n\n\n(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))\n\n\nShow the code\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "topics/intro.html",
    "href": "topics/intro.html",
    "title": "Moving beyond linearity",
    "section": "",
    "text": "Show the code\n\nimport pandas as pd\n\nimport numpy as np\n\nimport os\n\nfrom patsy import dmatrix\n\nfrom sklearn.linear_model import LinearRegression\n\nimport pygam\n\nfrom statsmodels.nonparametric.smoothers_lowess import lowess\n\n# Plot predictions\nimport matplotlib.pyplot as plt\n\n\n\n\nShow the code\n\nraw_df = pd.read_csv(os.path.join(os.path.expanduser(\"~\\\\Documents\\\\BOI_DL_website\"), \"data\\\\Wage.csv\"))\n\ny_vec = raw_df[\"wage\"].copy()\n\nx_vec = raw_df[[\"age\"]].copy()\n\n\n\n\nShow the code\n\ndef plot_predictions(pred_df, title):\n  pred_cols = [temp_name for temp_name in pred_df.columns.values if \"pred\" in temp_name]\n\n  plt.figure(figsize=(10, 6))\n  plt.scatter(pred_df[\"age\"], pred_df[\"wage\"], label=\"Actual Wage\", alpha = 0.7)\n\n  for temp_name in pred_cols:\n    plt.scatter(pred_df[\"age\"], pred_df[temp_name], label=temp_name, alpha = 0.7)\n#  plt.scatter(pred_df[\"age\"], pred_df[\"wage_pred\"], label=\"Predicted Wage\", alpha = 0.7)\n  plt.xlabel(\"Age\")\n  plt.ylabel(\"Wage\")\n  plt.title(title)\n  plt.legend()\n  plt.grid(True)\n  plt.show()\n\n\n\nPolynomial regression\n\nConstruct polynomial features:\n\nUsing the dmatrix function, create a feature matrix that includes polynomial terms up to the fourth degree: \\(\\text{age}, \\text{age}^2, \\text{age}^3, \\text{age}^4\\)\n\nFit a linear regression model:\n\nUse LinearRegression from sklearn and set fit_intercept=False since the intercept is already included in the design matrix.\nFit the model to predict y_vec from the polynomial features.\n\nMake predictions:\n\nUse the trained model to generate predictions for y_vec.\n\n\n\n\nShow the code\npoly_x_mat = dmatrix(\"age + I(age**2) + I(age**3) + I(age**4)\", x_vec)\n\nlin_reg = LinearRegression(fit_intercept=False)\n\nlin_reg.fit(poly_x_mat.copy(), y_vec)\n\n\nLinearRegression(fit_intercept=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nFalse\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nShow the code\n\npoly_pred = lin_reg.predict(poly_x_mat.copy())\n\n\n\nVisualize the results (optional but recommended):\n\n\n\nShow the code\nplot_predictions(pd.DataFrame({\"age\": x_vec[\"age\"], \"wage\": y_vec, \"wage_pred\": poly_pred}),\n                 \"Polynomial Regression\")\n\n\n\n\n\n\n\n\n\n\n\nStep functions\n\nDefine step function intervals (bins):\n\nUse np.percentile to determine cutoff points (knots) that divide age into quartiles.\n\nUse pd.cut to assign each age value to a bin.\n\nCreate a step function design matrix:\n\nUse the dmatrix function to encode the binned age values as categorical variables.\n\nFit a linear regression model:\n\nUse LinearRegression from sklearn and set fit_intercept=False since the intercept is already included in the design matrix.\nFit the model to predict y_vec based on the step function representation of age.\n\nMake predictions:\n\nUse the trained model to generate predictions for y_vec.\n\n\nHints:\n* Ensure that the step function bins do not have duplicate edges, which can be handled using duplicates='drop' in pd.cut.\n* You can use matplotlib.pyplot or seaborn to visualize the stepwise fitted function.\n* Since this is a piecewise constant model, expect a regression curve with horizontal segments rather than a smooth curve.\n\n\nShow the code\nknots = np.percentile(x_vec[\"age\"], [0, 15, 25, 50, 75,90, 100])\n\nx_vec_step = pd.cut(x_vec[\"age\"], bins=knots, labels=False,\n                    include_lowest=True,duplicates='drop')\n\nstep_x_mat = dmatrix(\"C(x_vec_step)\", x_vec_step)\n\nlin_reg = LinearRegression(fit_intercept=False)\n\nlin_reg.fit(step_x_mat.copy(), y_vec)\n\n\nLinearRegression(fit_intercept=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nFalse\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nShow the code\n\nstep_pred = lin_reg.predict(step_x_mat.copy())\n\n\n\nVisualize the results (optional but recommended):\n\n\n\nShow the code\nplot_predictions(pd.DataFrame({\"age\": x_vec[\"age\"], \"wage\": y_vec, \"wage_pred\": step_pred}), \"Step Regression\")\n\n\n\n\n\n\n\n\n\n\n\nPiecewise polynomials\n\nDefine the knot location:\n\nSet a single knot at age = 50 to allow for a change in the polynomial relationship at this point.\n\nCreate piecewise polynomial terms:\n\n\nConstruct polynomial terms (age, age², age³) for the entire dataset.\nDefine separate squared and cubic terms for values below and above the knot to allow for discontinuity.\nUse np.maximum to ensure that terms are active only in their respective regions.\n\n\nCreate a design matrix:\n\nCombine all polynomial terms into a matrix that serves as input for the regression model.\n\nFit a linear regression model:\n\nUse LinearRegression from sklearn and set fit_intercept=False since the intercept is already included in the design matrix.\nFit the model to predict y_vec based on the spline-transformed age values.\n\nMake predictions:\nUse the trained model to generate predictions for y_vec.\n\nHints:\n* B-splines create smooth, continuous fits by combining piecewise polynomial segments.\n* You can experiment with additional knots to see how the flexibility of the model changes.\n* Use matplotlib.pyplot or seaborn to visualize the fitted curve.\n\n\nShow the code\nknot = 50\n\n# Manually create piecewise terms to enforce discontinuity at the knot\nx_less_knot = np.maximum(0, knot - x_vec)  # For x &lt; knot\nx_greater_knot = np.maximum(0, x_vec - knot)  # For x &gt;= knot\n\n# Combine the terms into a design matrix (manual spline basis)\nspline_x_mat = np.column_stack((x_vec, x_vec**2, x_vec**3, x_less_knot**2,\n                                x_greater_knot**2,x_less_knot**3, x_greater_knot**3))\n\nlin_reg = LinearRegression(fit_intercept=False)\n\nlin_reg.fit(spline_x_mat.copy(), y_vec)\n\n\nLinearRegression(fit_intercept=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nFalse\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nShow the code\nspline_pred = lin_reg.predict(spline_x_mat.copy())\n\nlin_reg = LinearRegression(fit_intercept=False)\n\nlin_reg.fit(spline_x_mat.copy(), y_vec)\n\n\nLinearRegression(fit_intercept=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nFalse\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nShow the code\n\nspline_pred = lin_reg.predict(spline_x_mat.copy())\n\n\n\nVisualize the results (optional but recommended):\n\n\n\nShow the code\nplot_predictions(pd.DataFrame({\"age\": x_vec[\"age\"], \"wage\": y_vec, \"wage_pred\": spline_pred}),\n\"Piecewise Spline Regression\")\n\n\n\n\n\n\n\n\n\n\n\nSplines\n\nConstruct spline basis matrices:\n\nUse the dmatrix function to create a B-spline basis with knots at age = 25, 40, 60 and a polynomial degree of 3.\nUse the dmatrix function to create a natural spline basis with the same knots.\n\nFit linear regression models:\n\nUse LinearRegression from sklearn and set fit_intercept=False since the intercept is already included in the design matrix.\nFit one model using the B-spline basis and another using the natural spline basis.\n\nMake predictions:\nUse each trained model to generate predictions for y_vec.\n\nHints:\n* B-splines allow local flexibility, adjusting the curve within defined knots.\n* Natural splines impose additional constraints that make the curve behave more smoothly at the boundaries.\n* Try adjusting the number and position of knots to see how the model changes.\n* Use matplotlib.pyplot or seaborn to visualize the fitted curves.\n\n\nShow the code\nspline_x_mat = dmatrix(\"bs(age, knots = [25,40,60], degree=3)\", x_vec)\n\nnatural_spline_x_mat = dmatrix(\"cr(age, knots = [25,40,60])\", x_vec)\n\nlin_reg = LinearRegression(fit_intercept=False)\n\nlin_reg.fit(spline_x_mat.copy(), y_vec)\n\n\nLinearRegression(fit_intercept=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nFalse\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nShow the code\nspline_pred = lin_reg.predict(spline_x_mat.copy())\n\nlin_reg = LinearRegression(fit_intercept=False)\n\nlin_reg.fit(natural_spline_x_mat.copy(), y_vec)\n\n\nLinearRegression(fit_intercept=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nFalse\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\nShow the code\n\nnatural_spline_pred = lin_reg.predict(natural_spline_x_mat.copy())\n\n\n\nVisualize the results (optional but recommended):\n\n\n\nShow the code\nplot_predictions(pd.DataFrame({\"age\": x_vec[\"age\"], \"wage\": y_vec,\n                               \"spline_pred\": spline_pred,\n                               \"natural_spline_pred\": natural_spline_pred}),\n                               \"Spline and Natural spline Regression\")\n\n\n\n\n\n\n\n\n\n\n\nGeneral Additive Models\n\nPrepare features\n\nKeep year and age as numeric.\n\nEncode education as a categorical variable.\n\nSpecify the model\n\nUse smooth terms s() for year and age.\n\nUse f() for the categorical factor education.\n\nFit the model\n\nFit a LinearGAM to the training data.\n\n\n\n\nShow the code\nfrom pygam import LinearGAM, s, f\n\n# Encode categorical variable 'education'\nraw_df['education_code'] = raw_df['education'].astype('category').cat.codes\n\n# Features and response\nX = raw_df[['year', 'age', 'education_code']].values\n\ny = raw_df['wage'].values\n\n# Fit the GAM model\n\ngam = LinearGAM(s(0, n_splines=8) + s(1, n_splines=8) + f(2));\n\ngam.fit(X, y);\n\n\n\nVisualize the results\n\nPlot partial dependence for each term:\n\nsmooth curve for year\n\nsmooth curve for age\n\nbar chart for education\n\n\n\n\n\nShow the code\n# Generate smooth predictions for each term\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Plot the effect of year\nyear_grid = np.linspace(raw_df['year'].min(), raw_df['year'].max(), 100)\nX_year = np.zeros((100, 3))\nX_year[:, 0] = year_grid\naxes[0].plot(year_grid, gam.partial_dependence(0, X=X_year), color='red');\naxes[0].set_title(r\"$f_1(\\mathrm{year})$\");\naxes[0].set_xlabel(\"year\");\naxes[0].set_ylabel(\"Effect\");\naxes[0].set_ylim(-30, 30);\n\n# Plot the effect of age\nage_grid = np.linspace(raw_df['age'].min(), raw_df['age'].max(), 100)\nX_age = np.zeros((100, 3))\nX_age[:, 1] = age_grid\naxes[1].plot(age_grid, gam.partial_dependence(1, X=X_age), color='red');\naxes[1].set_title(r\"$f_2(\\mathrm{age})$\");\naxes[1].set_xlabel(\"age\");\naxes[1].set_ylabel(\"Effect\");\naxes[1].set_ylim(-50, 40);\n\n# Plot the effect of education\neducation_levels = np.sort(raw_df['education_code'].unique())\nX_edu = np.zeros((len(education_levels), 3))\nX_edu[:, 2] = education_levels\naxes[2].bar(\n    raw_df['education'].astype('category').cat.categories,\n    gam.partial_dependence(2, X=X_edu).flatten(),\n    color='red'\n);\naxes[2].set_title(r\"$f_3(\\mathrm{education})$\");\naxes[2].set_xlabel(\"education\");\naxes[2].set_ylabel(\"Effect\");\n\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html",
    "href": "topics/multi_layer/optim_methods.html",
    "title": "Optimization Methods in Neural Networks",
    "section": "",
    "text": "Implement and evaluate different optimization strategies for training a simple neural network",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#model",
    "href": "topics/multi_layer/optim_methods.html#model",
    "title": "Optimization Methods in Neural Networks",
    "section": "Model",
    "text": "Model\n\n\nShow the code\n\nlayer_dims = [2, 4, 1]\n\ngd_parameters, gd_costs = model(\n    X, y, layer_dims,\n    optimizer=\"gd\",\n    learning_rate=0.01,\n    num_epochs=params[\"num_epochs\"],\n    batch_size=X.shape[1],      # full batch for GD\n    print_cost=False,\n    print_every=params[\"num_prints\"]\n)",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#predictions",
    "href": "topics/multi_layer/optim_methods.html#predictions",
    "title": "Optimization Methods in Neural Networks",
    "section": "Predictions",
    "text": "Predictions\n\n\nShow the code\npred_gd = predict_nn(X, gd_parameters)\n\ngd_score = accuracy_score(pred_gd.flatten(),y.flatten())\n\nprint(f\"GD accuracy score is {gd_score}\")\n\n\nGD accuracy score is 0.215",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#model-1",
    "href": "topics/multi_layer/optim_methods.html#model-1",
    "title": "Optimization Methods in Neural Networks",
    "section": "Model",
    "text": "Model\n\n\nShow the code\n\nsgd_parameters, sgd_costs = model(\n    X, y, layer_dims,\n    optimizer=\"gd\",\n    learning_rate=0.01,\n    num_epochs=params[\"num_epochs\"],\n    batch_size=32,\n    print_cost=False,\n    print_every=params[\"num_prints\"]\n)",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#predictions-1",
    "href": "topics/multi_layer/optim_methods.html#predictions-1",
    "title": "Optimization Methods in Neural Networks",
    "section": "Predictions",
    "text": "Predictions\n\n\nShow the code\npred_sgd = predict_nn(X, sgd_parameters)\n\nsgd_score = accuracy_score(pred_sgd.flatten(),y.flatten())\n\nprint(f\"SGD accuracy score is {sgd_score}\")\n\n\nSGD accuracy score is 0.845",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#model-2",
    "href": "topics/multi_layer/optim_methods.html#model-2",
    "title": "Optimization Methods in Neural Networks",
    "section": "Model",
    "text": "Model\n\n\nShow the code\n\nmomentum_parameters, momentum_costs = model(\n    X, y, layer_dims,\n    optimizer=\"momentum\",\n    learning_rate=0.01,\n    num_epochs=params[\"num_epochs\"],\n    batch_size=X.shape[1],\n    print_cost=False,\n    print_every=params[\"num_prints\"],\n    beta = 0.9\n)",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#predictions-2",
    "href": "topics/multi_layer/optim_methods.html#predictions-2",
    "title": "Optimization Methods in Neural Networks",
    "section": "Predictions",
    "text": "Predictions\n\n\nShow the code\npred_momentum = predict_nn(X, momentum_parameters)\n\nmomentum_score = accuracy_score(pred_momentum.flatten(),y.flatten())\n\nprint(f\"Momentum accuracy score is {momentum_score}\")\n\n\nMomentum accuracy score is 0.846",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#model-3",
    "href": "topics/multi_layer/optim_methods.html#model-3",
    "title": "Optimization Methods in Neural Networks",
    "section": "Model",
    "text": "Model\n\n\nShow the code\n\nrmsprop_parameters, rmsprop_costs = model(\n    X, y, layer_dims,\n    optimizer=\"rmsprop\",\n    learning_rate=0.001,\n    num_epochs=params[\"num_epochs\"],\n    batch_size=X.shape[1],\n    print_cost=False,\n    print_every=params[\"num_prints\"],\n    beta2 = 0.9,\n    epsilon = 1 * 10 ** (-8)\n)",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#predictions-3",
    "href": "topics/multi_layer/optim_methods.html#predictions-3",
    "title": "Optimization Methods in Neural Networks",
    "section": "Predictions",
    "text": "Predictions\n\n\nShow the code\npred_rmsprop = predict_nn(X, rmsprop_parameters)\n\nrmsprop_score = accuracy_score(pred_rmsprop.flatten(),y.flatten())\n\nprint(f\"RMSProp accuracy score is {rmsprop_score}\")\n\n\nRMSProp accuracy score is 0.232",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#model-4",
    "href": "topics/multi_layer/optim_methods.html#model-4",
    "title": "Optimization Methods in Neural Networks",
    "section": "Model",
    "text": "Model\n\n\nShow the code\n\nadam_parameters, adam_costs = model(\n    X, y, layer_dims,\n    optimizer=\"adam\",\n    learning_rate=0.001,\n    num_epochs=params[\"num_epochs\"],\n    batch_size=X.shape[1],\n    print_cost=False,\n    print_every=params[\"num_prints\"],\n    beta = 0.9,\n    beta2 = 0.999,\n    epsilon = 1 * 10 ** (-8)\n)",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/multi_layer/optim_methods.html#predictions-4",
    "href": "topics/multi_layer/optim_methods.html#predictions-4",
    "title": "Optimization Methods in Neural Networks",
    "section": "Predictions",
    "text": "Predictions\n\n\nShow the code\npred_adam = predict_nn(X, adam_parameters)\n\nadam_score = accuracy_score(pred_adam.flatten(),y.flatten())\n\nprint(f\"Adam accuracy score is {adam_score}\")\n\n\nAdam accuracy score is 0.605",
    "crumbs": [
      "Optimization methods"
    ]
  },
  {
    "objectID": "topics/rnn/rnn.html",
    "href": "topics/rnn/rnn.html",
    "title": "Recurrent Neural Network for Time Series Forecasting",
    "section": "",
    "text": "This tutorial demonstrates how to use recurrent neural networks to forecast financial time series data. We will work with daily Dow Jones data and predict the next day’s log trading volume using information from the previous ten days. The analysis includes two recurrent neural architectures—RNN and GRU—used to forecast next-day log trading volume.\n\nFeature engineering\nBefore training the models, we perform several feature-engineering steps to extract informative signals from the raw data. We compute the log of trading volume, daily log-returns, and a 10-day rolling estimate of volatility. These features capture trading activity, price movements, and short-term uncertainty, forming the three inputs used by the models.\n\n\n\n\n\n\n\n\n\nWe construct input sequences of 10 consecutive time steps, where each sequence is used to predict the following observation. After building these sequences, we split the dataset into training and testing subsets to evaluate model performance.\nBecause neural networks are sensitive to the scale of their inputs, we standardize both the feature sequences and the target variable. Each feature is transformed to have zero mean and unit variance based on the training set only. This ensures stable training and prevents information from the test set from leaking into the model during preprocessing.\nWe now build two recurrent neural network architectures commonly used for sequential data. Each model receives a 10×3 input window (log volume, return, and log volatility) and predicts the next day’s log volume:\n\nSimpleRNN — a basic recurrent unit suitable for short-range dependencies.\n\nGRU — a gated recurrent unit capable of capturing longer patterns with fewer parameters than LSTM.\n\nBoth models use 12 hidden units and are trained for 30 epochs.\n\n\nModels fit\n\n\nEvaluation\nAfter training all models, we evaluate their performance on the test set using standard regression metrics. These metrics quantify different aspects of forecast accuracy:\n\nRMSE (Root Mean Squared Error): penalizes larger errors more heavily.\n\nMAE (Mean Absolute Error): reflects typical forecast error in the original units.\n\nR² (Coefficient of Determination): measures how much of the variance in the true values is explained by the model.\n\nComparing these values across the two recurrent models allows us to assess how SimpleRNN and GRU differ in accuracy and whether the additional gating mechanisms in GRU provide a measurable improvement.\n\n\n\n=== Model Performance Comparison ===\n\n\n    Model     RMSE      MAE       R²\n      GRU 0.208014 0.145228 0.243159\nSimpleRNN 0.228411 0.161641 0.087461\n\n\nTo visually compare model behavior, we plot the first 200 predictions from the test set. This shows how closely the SimpleRNN and GRU models follow the true log-volume values over time. A well-performing model should track both the overall level and the short-term fluctuations of the series."
  },
  {
    "objectID": "topics/single_layer/regression.html",
    "href": "topics/single_layer/regression.html",
    "title": "Single layer Neural Network for Regression",
    "section": "",
    "text": "Implement a simple neural network from scratch and compare its performance to linear regression on a 2D dataset.\nShow the code\n\nimport pandas as pd\n\nimport numpy as np\n\nimport os",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/single_layer/regression.html#auxiliary-functions",
    "href": "topics/single_layer/regression.html#auxiliary-functions",
    "title": "Single layer Neural Network for Regression",
    "section": "Auxiliary functions",
    "text": "Auxiliary functions\n\nImplement Training Functions\n\nDefine helper functions for activation, parameter initialization, forward/backward propagation, and parameter update.\n\n\n\nShow the activation function code\nimport numpy as np\n\n\ndef activate(Z, activation_function=\"tanh\"):\n    \"\"\"\n    Apply an activation function elementwise.\n    \"\"\"\n    if activation_function == \"tanh\":\n        return np.tanh(Z)  # squashes values to [-1, 1]\n    elif activation_function == \"sigmoid\":\n        return 1.0 / (1.0 + np.exp(-Z))  # squashes values to [0, 1]\n    else:\n        raise ValueError(\"activation_function must be 'tanh' or 'sigmoid'.\")\n\n\n\n\nShow the parameters initialization code\nimport numpy as np\n\n\ndef initialize_parameters(X, num_hidden_layer_neurons, scale_const=0.01, seed=1):\n    \"\"\"\n    Initialize weights and biases for a single hidden-layer network.\n    \"\"\"\n    np.random.seed(seed)\n\n    n_features = X.shape[1]  # number of input features\n\n    # Small random weights help avoid saturation of activations at start\n    W1 = np.random.randn(num_hidden_layer_neurons, n_features) * scale_const\n    b1 = np.zeros((num_hidden_layer_neurons, 1))\n    W2 = np.random.randn(1, num_hidden_layer_neurons) * scale_const\n    b2 = np.zeros((1, 1))\n\n    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n\n\n\n\n\nForward and backward propagation in a single-hidden-layer neural network. The forward pass takes inputs \\(X\\) through weights \\(W^{[1]}, W^{[2]}\\) and biases \\(b^{[1]}, b^{[2]}\\) to produce pre-activations \\(Z^{[1]}, Z^{[2]}\\), activations \\(A^{[1]}, A^{[2]}\\), and final output \\(y\\). The backward pass computes gradients of activations, pre-activations, weights, and biases \\((dA, dZ, dW, db)\\) from the output layer back to the input layer for parameter updates.\n\n\n\n\nShow the forward propagation code\nimport numpy as np\n\ndef forward_propagation(parameters, X_adj):\n    \"\"\"\n    Perform one forward pass (regression: linear output).\n    \"\"\"\n    W1, b1 = parameters[\"W1\"], parameters[\"b1\"]\n    W2, b2 = parameters[\"W2\"], parameters[\"b2\"]\n\n    Z1 = np.dot(W1, X_adj) + b1      # hidden layer affine transform\n    A1 = activate(Z1, \"tanh\")        # hidden nonlinearity\n    Z2 = np.dot(W2, A1) + b2         # output layer affine transform\n    A2 = Z2                          # linear output for regression\n\n    return {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n\n\n\n\nShow the backward propagation code\nimport numpy as np\n\ndef backward_propagation(parameters, forward_propagation_values, X_adj, Y_adj):\n    \"\"\"\n    Compute gradients for parameters using backpropagation (MSE loss, linear output).\n    \"\"\"\n    N = X_adj.shape[1]  # number of samples\n\n    W2 = parameters[\"W2\"]\n    A1, A2 = forward_propagation_values[\"A1\"], forward_propagation_values[\"A2\"]\n\n    # Output layer: for MSE with linear output, dZ2 = A2 - Y\n    dZ2 = A2 - Y_adj\n    dW2 = np.dot(dZ2, A1.T) / N\n    db2 = np.sum(dZ2, axis=1, keepdims=True) / N\n\n    # Hidden layer\n    dZ1 = np.dot(W2.T, dZ2) * (1 - A1**2)\n    dW1 = np.dot(dZ1, X_adj.T) / N\n    db1 = np.sum(dZ1, axis=1, keepdims=True) / N\n\n    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n\n\n\n\nShow the parameters update code\nimport numpy as np\n\ndef update_parameters(parameters, grads, learning_rate=0.01):\n    \"\"\"\n    Update parameters using gradient descent.\n    \"\"\"\n    # subtract learning_rate * gradient for each parameter\n    W1 = parameters[\"W1\"] - learning_rate * grads[\"dW1\"]\n    b1 = parameters[\"b1\"] - learning_rate * grads[\"db1\"]\n    W2 = parameters[\"W2\"] - learning_rate * grads[\"dW2\"]\n    b2 = parameters[\"b2\"] - learning_rate * grads[\"db2\"]\n\n    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n\n\n\nCreate a wrapper function train_neural_network to run the training loop.\n\n\n\nShow the neural network training code\ndef train_neural_network(X, Y, num_iterations, num_hidden_layer_neurons=4):\n    \"\"\"\n    Trains a simple 1-hidden-layer neural network using gradient descent.\n    \"\"\"\n    # Transpose X so columns are examples, reshape Y to row vector\n    X_adj = X.T.copy()                         \n    Y_adj = Y.values.reshape(1, -1).copy()     \n\n    # Initialize weights and biases\n    parameters = initialize_parameters(X, num_hidden_layer_neurons=num_hidden_layer_neurons)\n\n    for iteration in range(num_iterations):\n        # Forward pass\n        forward_values = forward_propagation(parameters, X_adj.copy())\n\n        # Backward pass\n        grads = backward_propagation(parameters, forward_values, X_adj.copy(), Y_adj.copy())\n\n        # Parameter update\n        parameters = update_parameters(parameters, grads)\n\n    return parameters\n\n\n\n\nImplement Prediction Function\n\nCreate a predict function that runs forward propagation and returns continuous outputs.\n\n\n\nShow the code\ndef predict(nn_parameters, X):\n    \"\"\"\n    Generates continuous predictions from a trained neural network (regression).\n    \"\"\"\n    # Transpose X so columns are examples\n    X_adj = X.T.copy()\n\n    # Forward pass to get output layer values\n    forward_values = forward_propagation(nn_parameters, X_adj.copy())\n\n    # For regression, output is linear (A2)\n    return forward_values[\"A2\"].ravel()",
    "crumbs": [
      "Regression"
    ]
  },
  {
    "objectID": "topics/temp.html",
    "href": "topics/temp.html",
    "title": "Preprocess",
    "section": "",
    "text": "Show the code\n\n# === Imports ===\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Ensure eager execution (important for reticulate/Quarto)\ntf.config.run_functions_eagerly(True)\n\n\n\n\nLoad and clean CPI data\n# === Load CPI panel dataset ===\ncpi_data_path = os.path.join(\n  os.path.expanduser(\"~\\\\Documents\\\\BOI_DL_website\"),\n  \"data\\\\cpi_series.csv\"\n)\n\ncpi_raw = pd.read_csv(cpi_data_path)\n\n# === Basic cleaning ===\n# Parse dates\ncpi_raw['timestamp'] = pd.to_datetime(cpi_raw['timestamp'])\n\n# Sort properly\ncpi_raw = cpi_raw.sort_values(['item_id', 'timestamp']).reset_index(drop=True)\n\n# Keep only necessary columns (item_id, timestamp, target)\ncpi_raw = cpi_raw[['item_id', 'timestamp', 'target']].dropna().reset_index(drop=True)\n\n\n\n\nLoad and clean CPI data\ndef assign_splits_per_series(df, train_ratio=0.70, val_ratio=0.15):\n    \"\"\"\n    Assign 'train', 'val', 'test' labels within EACH series\n    based strictly on time order.\n    \"\"\"\n    df = df.copy()\n    df[\"split\"] = None\n\n    for code in df[\"item_code\"].unique():\n        df_i = df[df[\"item_code\"] == code].sort_values(\"timestamp\")\n        idx = df_i.index.to_numpy()\n\n        n = len(idx)\n        t_end = int(n * train_ratio)\n        v_end = int(n * (train_ratio + val_ratio))\n\n        df.loc[idx[:t_end], \"split\"] = \"train\"\n        df.loc[idx[t_end:v_end], \"split\"] = \"val\"\n        df.loc[idx[v_end:], \"split\"] = \"test\"\n\n    return df\n\n\n\ndef preprocess_data(cpi_raw, selected_series, train_ratio=0.70, val_ratio=0.15):\n    \"\"\"\n    Preprocess CPI panel data WITHOUT leakage:\n      - filter selected series\n      - sort by timestamp\n      - assign integer item codes\n      - assign per-series splits\n      - scale each series using only its training segment\n      - return dataframe + scalers\n    \"\"\"\n\n    # --- Filter ---\n    df = cpi_raw.loc[cpi_raw[\"item_id\"].isin(selected_series)].copy()\n    df = df.sort_values([\"item_id\", \"timestamp\"]).reset_index(drop=True)\n\n    # --- Assign integer codes ---\n    item_ids = df[\"item_id\"].unique().tolist()\n    item_to_int = {item_id: idx for idx, item_id in enumerate(item_ids)}\n    df[\"item_code\"] = df[\"item_id\"].map(item_to_int)\n\n    # --- Assign per-series splits (NO LEAKAGE) ---\n    df = assign_splits_per_series(df, train_ratio=train_ratio, val_ratio=val_ratio)\n\n    # --- Scale each series ONLY on its training portion ---\n    scalers = {}\n    df[\"target_scaled\"] = np.nan\n\n    for code in sorted(item_to_int.values()):\n        df_i = df[df[\"item_code\"] == code]\n\n        # fit scaler on TRAIN ONLY\n        train_vals = df_i[df_i[\"split\"] == \"train\"][\"target\"].values.reshape(-1, 1)\n        scaler = StandardScaler().fit(train_vals)\n\n        # transform all splits with same scaler\n        all_vals = df_i[\"target\"].values.reshape(-1, 1)\n        df.loc[df_i.index, \"target_scaled\"] = scaler.transform(all_vals).flatten()\n\n        scalers[code] = scaler\n\n    return df, scalers\n\n\n\ndef make_windows(cpi_df, WINDOW):\n    \"\"\"\n    Create sliding windows for a panel CPI dataset.\n    Returns pooled windows across all series:\n      X_windows : (N, WINDOW, 2)   # [target_scaled, item_code]\n      y_windows : (N,)             # next-step value (scaled)\n      t_windows : (N,)             # timestamp of the target point\n    \"\"\"\n\n    X_list = []\n    y_list = []\n    t_list = []\n\n    # Loop per item_code (per series)\n    for code in np.unique(cpi_df[\"item_code\"]):\n\n        df_i = cpi_df[cpi_df[\"item_code\"] == code]\n        vals = df_i[\"target_scaled\"].values\n        codes = df_i[\"item_code\"].values\n        ts    = df_i[\"timestamp\"].values\n\n        # Build windows for this series\n        for t in range(len(vals) - WINDOW):\n\n            # Sliding window values\n            w_target = vals[t:t+WINDOW].reshape(WINDOW, 1)\n            w_code   = np.full((WINDOW, 1), codes[0])\n\n            window = np.hstack([w_target, w_code])\n\n            X_list.append(window)\n            y_list.append(vals[t + WINDOW])\n            t_list.append(ts[t + WINDOW])   # target timestamp\n\n    # Convert to arrays\n    X_windows = np.array(X_list)\n    y_windows = np.array(y_list)\n    t_windows = np.array(t_list)\n\n    return X_windows, y_windows, t_windows\n\n\ndef split_by_time(X_all, y_all, t_all, train_ratio=0.70, val_ratio=0.15):\n    \"\"\"\n    Perform a global chronological split on pooled windowed data.\n    Inputs:\n        X_all : np.array (N, WINDOW, 2)\n        y_all : np.array (N,)\n        t_all : np.array (N,) timestamps aligned with y_all\n        train_ratio : fraction of samples for training\n        val_ratio   : fraction of samples for validation (after train)\n\n    Returns:\n        (X_train, y_train),\n        (X_val,   y_val),\n        (X_test,  y_test)\n    \"\"\"\n\n    # ---- 1. Sort globally by timestamp ----\n    order = np.argsort(t_all)\n    X_sorted = X_all[order]\n    y_sorted = y_all[order]\n    t_sorted = t_all[order]   # not strictly needed after this step, but kept\n\n    # ---- 2. Compute split indices ----\n    n = len(X_sorted)\n    train_end = int(n * train_ratio)\n    val_end   = int(n * (train_ratio + val_ratio))\n\n    # ---- 3. Slice ----\n    X_train = X_sorted[:train_end]\n    y_train = y_sorted[:train_end]\n\n    X_val   = X_sorted[train_end:val_end]\n    y_val   = y_sorted[train_end:val_end]\n\n    X_test  = X_sorted[val_end:]\n    y_test  = y_sorted[val_end:]\n\n    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n\n\ndef prepare_all_inputs(X_train, X_val, X_test, WINDOW):\n    \"\"\"Prepare series and item-code inputs for the model.\"\"\"\n\n    return {\n        \"train_series\": X_train[:, :, 0].reshape(-1, WINDOW, 1),\n        \"train_code\":   X_train[:, 0, 1].reshape(-1, 1),\n\n        \"val_series\":   X_val[:, :, 0].reshape(-1, WINDOW, 1),\n        \"val_code\":     X_val[:, 0, 1].reshape(-1, 1),\n\n        \"test_series\":  X_test[:, :, 0].reshape(-1, WINDOW, 1),\n        \"test_code\":    X_test[:, 0, 1].reshape(-1, 1),\n    }\n\n\n\ndef build_model(num_items: int, window: int, embed_dim: int = 8):\n    \"\"\"\n    Build the global RNN model with:\n    - item embedding\n    - 2-layer GRU stack\n    - dense head\n    \"\"\"\n    from tensorflow.keras import layers, models\n    import tensorflow as tf\n\n    # === Inputs ===\n    inp_series = layers.Input(shape=(window, 1), name=\"series_input\")\n    inp_code   = layers.Input(shape=(1,), name=\"item_code_input\")\n\n    # === Embedding ===\n    emb = layers.Embedding(\n        input_dim=num_items,\n        output_dim=embed_dim\n    )(inp_code)\n\n    emb = layers.Reshape((embed_dim,))(emb)\n    emb = layers.RepeatVector(window)(emb)   # broadcast to full sequence length\n\n    # === Merge ===\n    x = layers.Concatenate(axis=-1)([inp_series, emb])   # shape (window, 1 + embed_dim)\n\n    # === RNN stack ===\n    x = layers.GRU(128, return_sequences=True)(x)\n    x = layers.Dropout(0.1)(x)\n\n    x = layers.GRU(32, return_sequences=False)(x)\n    x = layers.Dropout(0.1)(x)\n\n    # === Dense head ===\n    x = layers.Dense(32, activation=\"relu\")(x)\n    x = layers.Dense(16, activation=\"relu\")(x)\n\n    # === Output ===\n    out = layers.Dense(1)(x)\n\n    # === Build model ===\n    model = models.Model(inputs=[inp_series, inp_code], outputs=out)\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        loss=\"mse\",\n        metrics=[\"mae\"]\n    )\n\n    return model\n\ndef get_predictions(model, X_series, X_code, y_scaled, scalers):\n    \"\"\"\n    Complete prediction pipeline:\n      1. Predict in scaled space\n      2. Invert scale of predictions\n      3. Invert scale of true values\n\n    Inputs:\n        model      : trained Keras model\n        X_series   : (N, WINDOW, 1)\n        X_code     : (N, 1) integer item code\n        y_scaled   : (N,) true values in scaled space\n        scalers    : dict {code → StandardScaler}\n\n    Returns:\n        y_pred        : predictions in original scale\n        y_true        : true values in original scale\n        y_pred_scaled : predictions in scaled units\n    \"\"\"\n\n    # --- 1. scaled predictions ---\n    y_pred_scaled = model.predict([X_series, X_code], verbose=0).flatten()\n\n    # --- 2. inverse-transform predictions ---\n    y_pred = np.zeros_like(y_pred_scaled)\n\n    # --- 3. inverse-transform true values ---\n    y_true = np.zeros_like(y_scaled)\n\n    for i in range(len(y_pred_scaled)):\n        code = int(X_code[i][0])\n        scaler = scalers[code]\n\n        y_pred[i] = scaler.inverse_transform([[y_pred_scaled[i]]])[0][0]\n        y_true[i] = scaler.inverse_transform([[y_scaled[i]]])[0][0]\n\n    return y_pred, y_true, y_pred_scaled\n\n\n\nPreprocess\n\nselected_series = [\"CP000000_CPI_CPI_5_0_3_MAIN_M_N__Z__Z_I24_L__Z_A__Z__Z_CP_00\",\n                   \"CP010000_CPI_CPI_5_1_8_MAIN_M_N__Z__Z_I24_L__Z_A__Z__Z_CP_01\"]\n                   \ncpi_df, scalers = preprocess_data(cpi_raw, selected_series)\n\ncpi_df.head()\n\n                                             item_id  ... target_scaled\n0  CP000000_CPI_CPI_5_0_3_MAIN_M_N__Z__Z_I24_L__Z...  ...     -0.842173\n1  CP000000_CPI_CPI_5_0_3_MAIN_M_N__Z__Z_I24_L__Z...  ...     -0.842174\n2  CP000000_CPI_CPI_5_0_3_MAIN_M_N__Z__Z_I24_L__Z...  ...     -0.842178\n3  CP000000_CPI_CPI_5_0_3_MAIN_M_N__Z__Z_I24_L__Z...  ...     -0.842160\n4  CP000000_CPI_CPI_5_0_3_MAIN_M_N__Z__Z_I24_L__Z...  ...     -0.842174\n\n[5 rows x 6 columns]\n\n\n\n# --- Correct panel-aware time-based split (timestamp-preserving) ---\n\n\nWINDOW = 36\nX_all, y_all, t_all = make_windows(cpi_df, WINDOW)\n\n(X_train, y_train), (X_val, y_val), (X_test, y_test) = split_by_time(\n    X_all, y_all, t_all\n)\n\n\n\nPrepare model inputs\ninputs = prepare_all_inputs(X_train, X_val, X_test, WINDOW)\n\nX_train_series = inputs[\"train_series\"]\nX_train_code   = inputs[\"train_code\"]\n\nX_val_series   = inputs[\"val_series\"]\nX_val_code     = inputs[\"val_code\"]\n\nX_test_series  = inputs[\"test_series\"]\nX_test_code    = inputs[\"test_code\"]\n\n\nprint(\"Series input:\", X_train_series.shape)\n\n\nSeries input: (1027, 36, 1)\n\n\nPrepare model inputs\nprint(\"Item code input:\", X_train_code.shape)\n\n\nItem code input: (1027, 1)\n\n\n\n\nFit model\n\n\nBuild Global RNN with item embedding\nNUM_ITEMS = len(cpi_df[\"item_code\"].unique())   # comes from preprocess step\n\nmodel = build_model(\n    num_items=NUM_ITEMS,\n    window=WINDOW,\n    embed_dim=8\n)\n\nmodel.summary()\n\n\nModel: \"functional\"\n┌─────────────────────┬───────────────────┬────────────┬───────────────────┐\n│ Layer (type)        │ Output Shape      │    Param # │ Connected to      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ item_code_input     │ (None, 1)         │          0 │ -                 │\n│ (InputLayer)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (None, 1, 8)      │         16 │ item_code_input[… │\n│ (Embedding)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape (Reshape)   │ (None, 8)         │          0 │ embedding[0][0]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ series_input        │ (None, 36, 1)     │          0 │ -                 │\n│ (InputLayer)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ repeat_vector       │ (None, 36, 8)     │          0 │ reshape[0][0]     │\n│ (RepeatVector)      │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (None, 36, 9)     │          0 │ series_input[0][… │\n│ (Concatenate)       │                   │            │ repeat_vector[0]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ gru (GRU)           │ (None, 36, 128)   │     53,376 │ concatenate[0][0] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (Dropout)   │ (None, 36, 128)   │          0 │ gru[0][0]         │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ gru_1 (GRU)         │ (None, 32)        │     15,552 │ dropout[0][0]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (Dropout) │ (None, 32)        │          0 │ gru_1[0][0]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (Dense)       │ (None, 32)        │      1,056 │ dropout_1[0][0]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (Dense)     │ (None, 16)        │        528 │ dense[0][0]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (Dense)     │ (None, 1)         │         17 │ dense_1[0][0]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n Total params: 70,545 (275.57 KB)\n Trainable params: 70,545 (275.57 KB)\n Non-trainable params: 0 (0.00 B)\n\n\n\n\nTrain Global RNN\nEPOCHS = 50\nBATCH_SIZE = 32\n\n# Early stopping callback\ncb = EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,\n    restore_best_weights=True\n)\n\nhistory = model.fit(\n    x=[X_train_series, X_train_code],\n    y=y_train,\n    validation_data=([X_val_series, X_val_code], y_val),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    callbacks=[cb],\n    verbose=0\n)\n\n\nC:\\Users\\Home\\AppData\\Local\\Programs\\Python\\PYTHON~2\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n\n\n\n\nEvaluation\n\n\nPredict on test set (scaled units)\ny_pred, y_true, y_pred_scaled = get_predictions(\n    model,\n    X_test_series,\n    X_test_code,\n    y_test,\n    scalers\n)\n\n\n\n\nEvaluation metrics on test set (original scale)\nrmse = root_mean_squared_error(y_true, y_pred)\nmae  = mean_absolute_error(y_true, y_pred)\nr2   = r2_score(y_true, y_pred)\n\nmetrics_df = pd.DataFrame({\n\"RMSE\": [rmse],\n\"MAE\":  [mae],\n\"R2\":   [r2]\n})\n\nprint(metrics_df)\n\n\n       RMSE        MAE        R2\n0  19.44622  18.424192 -6.764344\n\n\n\n\nPlot predictions vs actual per series (2-column grid, original scale)\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntest_codes = X_test_code.flatten()\nunique_codes = np.unique(test_codes)\n\nfig, axes = plt.subplots(1, len(unique_codes), figsize=(16, 5), sharey=True)\n\nif len(unique_codes) == 1:\n  axes = [axes]\n\nfor ax, code in zip(axes, unique_codes):\n  mask = test_codes == code\n\n  ax.plot(y_true[mask], label=\"Actual\", color=\"black\", linewidth=2)\n  ax.plot(y_pred[mask], label=\"Predicted\", alpha=0.85)\n  \n  ax.set_title(f\"Item Code {code}\")\n  ax.set_xlabel(\"Time index\")\n  ax.grid(True)\n\n\naxes[0].set_ylabel(\"CPI Level\")\naxes[0].legend()\n  \nplt.tight_layout()\nplt.show()"
  }
]